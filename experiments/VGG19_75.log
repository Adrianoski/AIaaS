nohup: ignoring input
cuda:0
Network Improver initialization ...
-------------------------------------------------------------------------
Starting process with Accuracy:  0.75
-------------------------------------------------------------------------
Epoch 1/100, Train Loss: 1.662464, Train Acc: 37.91%, Val Loss: 1.315503, Val Acc: 52.64%
Epoch 2/100, Train Loss: 1.294457, Train Acc: 53.60%, Val Loss: 1.132218, Val Acc: 59.93%
Epoch 3/100, Train Loss: 1.093429, Train Acc: 61.53%, Val Loss: 1.025485, Val Acc: 63.73%
Epoch 4/100, Train Loss: 0.952748, Train Acc: 67.17%, Val Loss: 0.887508, Val Acc: 69.88%
Epoch 5/100, Train Loss: 0.848823, Train Acc: 70.94%, Val Loss: 0.834737, Val Acc: 72.36%
Epoch 6/100, Train Loss: 0.762276, Train Acc: 74.01%, Val Loss: 0.751048, Val Acc: 74.53%
Epoch 7/100, Train Loss: 0.698974, Train Acc: 76.31%, Val Loss: 0.729550, Val Acc: 74.55%
Epoch 8/100, Train Loss: 0.645697, Train Acc: 78.30%, Val Loss: 0.625774, Val Acc: 78.07%
Epoch 9/100, Train Loss: 0.596478, Train Acc: 79.98%, Val Loss: 0.659444, Val Acc: 78.00%
Epoch 10/100, Train Loss: 0.563516, Train Acc: 81.02%, Val Loss: 0.596092, Val Acc: 79.49%
Epoch 11/100, Train Loss: 0.528714, Train Acc: 82.37%, Val Loss: 0.597295, Val Acc: 80.30%
Epoch 12/100, Train Loss: 0.503366, Train Acc: 83.21%, Val Loss: 0.586292, Val Acc: 80.78%
Epoch 13/100, Train Loss: 0.478880, Train Acc: 84.03%, Val Loss: 0.528798, Val Acc: 81.88%
Epoch 14/100, Train Loss: 0.448426, Train Acc: 85.08%, Val Loss: 0.543489, Val Acc: 81.48%
Epoch 15/100, Train Loss: 0.427743, Train Acc: 85.77%, Val Loss: 0.525735, Val Acc: 82.03%
Epoch 16/100, Train Loss: 0.404790, Train Acc: 86.39%, Val Loss: 0.503765, Val Acc: 82.87%
Epoch 17/100, Train Loss: 0.389944, Train Acc: 87.04%, Val Loss: 0.538702, Val Acc: 82.67%
Epoch 18/100, Train Loss: 0.367782, Train Acc: 87.63%, Val Loss: 0.525330, Val Acc: 83.34%
Epoch 19/100, Train Loss: 0.353688, Train Acc: 88.07%, Val Loss: 0.486364, Val Acc: 84.07%
Epoch 20/100, Train Loss: 0.336453, Train Acc: 88.83%, Val Loss: 0.479542, Val Acc: 83.94%
Epoch 21/100, Train Loss: 0.322478, Train Acc: 89.24%, Val Loss: 0.475007, Val Acc: 85.26%
Epoch 22/100, Train Loss: 0.305767, Train Acc: 89.77%, Val Loss: 0.491219, Val Acc: 85.13%
Epoch 23/100, Train Loss: 0.291156, Train Acc: 90.27%, Val Loss: 0.423247, Val Acc: 86.34%
Epoch 24/100, Train Loss: 0.280828, Train Acc: 90.54%, Val Loss: 0.440814, Val Acc: 85.60%
Epoch 25/100, Train Loss: 0.274565, Train Acc: 90.88%, Val Loss: 0.466020, Val Acc: 85.01%
Epoch 26/100, Train Loss: 0.260137, Train Acc: 91.17%, Val Loss: 0.435975, Val Acc: 86.01%
Epoch 27/100, Train Loss: 0.245570, Train Acc: 91.71%, Val Loss: 0.468391, Val Acc: 86.00%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.862}]
Valore m[value]:  0.862
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 256 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 1.0
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (16): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (18): Sequential(
    (0): Linear(in_features=4096, out_features=4096, bias=True)
    (1): ReLU()
  )
  (19): Sequential(
    (0): Linear(in_features=4096, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (16): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (18): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
  )
  (19): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.746532, Train Acc: 34.69%, Val Loss: 1.451481, Val Acc: 47.91%
Epoch 2/100, Train Loss: 1.441173, Train Acc: 47.94%, Val Loss: 1.286427, Val Acc: 53.31%
Epoch 3/100, Train Loss: 1.290462, Train Acc: 53.71%, Val Loss: 1.178035, Val Acc: 57.15%
Epoch 4/100, Train Loss: 1.173348, Train Acc: 58.70%, Val Loss: 1.099736, Val Acc: 60.58%
Epoch 5/100, Train Loss: 1.078253, Train Acc: 61.68%, Val Loss: 0.996293, Val Acc: 65.09%
Epoch 6/100, Train Loss: 0.999420, Train Acc: 64.92%, Val Loss: 0.993641, Val Acc: 65.07%
Epoch 7/100, Train Loss: 0.931044, Train Acc: 67.48%, Val Loss: 0.858916, Val Acc: 69.94%
Epoch 8/100, Train Loss: 0.860932, Train Acc: 70.14%, Val Loss: 0.843468, Val Acc: 70.57%
Epoch 9/100, Train Loss: 0.809898, Train Acc: 71.93%, Val Loss: 0.804494, Val Acc: 71.79%
Epoch 10/100, Train Loss: 0.764094, Train Acc: 73.81%, Val Loss: 0.746683, Val Acc: 74.36%
Epoch 11/100, Train Loss: 0.721303, Train Acc: 75.15%, Val Loss: 0.789443, Val Acc: 72.96%
Epoch 12/100, Train Loss: 0.686044, Train Acc: 76.59%, Val Loss: 0.672904, Val Acc: 76.91%
Epoch 13/100, Train Loss: 0.659243, Train Acc: 77.35%, Val Loss: 0.680288, Val Acc: 76.69%
Epoch 14/100, Train Loss: 0.624008, Train Acc: 78.81%, Val Loss: 0.648758, Val Acc: 78.30%
Epoch 15/100, Train Loss: 0.601932, Train Acc: 79.30%, Val Loss: 0.631549, Val Acc: 78.38%
Epoch 16/100, Train Loss: 0.579395, Train Acc: 80.20%, Val Loss: 0.600217, Val Acc: 79.31%
Epoch 17/100, Train Loss: 0.564607, Train Acc: 80.68%, Val Loss: 0.594789, Val Acc: 79.36%
Epoch 18/100, Train Loss: 0.542997, Train Acc: 81.56%, Val Loss: 0.609205, Val Acc: 79.11%
Epoch 19/100, Train Loss: 0.510842, Train Acc: 82.57%, Val Loss: 0.588643, Val Acc: 79.81%
Epoch 20/100, Train Loss: 0.504895, Train Acc: 82.84%, Val Loss: 0.589731, Val Acc: 80.10%
Epoch 21/100, Train Loss: 0.484133, Train Acc: 83.50%, Val Loss: 0.552083, Val Acc: 81.24%
Epoch 22/100, Train Loss: 0.469325, Train Acc: 83.86%, Val Loss: 0.561508, Val Acc: 81.06%
Epoch 23/100, Train Loss: 0.452216, Train Acc: 84.63%, Val Loss: 0.545450, Val Acc: 81.48%
Epoch 24/100, Train Loss: 0.439672, Train Acc: 84.98%, Val Loss: 0.556656, Val Acc: 81.32%
Epoch 25/100, Train Loss: 0.432382, Train Acc: 85.26%, Val Loss: 0.549022, Val Acc: 81.93%
Epoch 26/100, Train Loss: 0.415952, Train Acc: 85.76%, Val Loss: 0.534240, Val Acc: 82.11%
Epoch 27/100, Train Loss: 0.398112, Train Acc: 86.42%, Val Loss: 0.553300, Val Acc: 81.60%
Epoch 28/100, Train Loss: 0.390820, Train Acc: 86.58%, Val Loss: 0.526035, Val Acc: 82.14%
Epoch 29/100, Train Loss: 0.383943, Train Acc: 86.83%, Val Loss: 0.528965, Val Acc: 82.33%
Epoch 30/100, Train Loss: 0.366937, Train Acc: 87.57%, Val Loss: 0.518334, Val Acc: 83.27%
Epoch 31/100, Train Loss: 0.355904, Train Acc: 87.75%, Val Loss: 0.530235, Val Acc: 82.59%
Epoch 32/100, Train Loss: 0.350306, Train Acc: 88.01%, Val Loss: 0.522592, Val Acc: 83.29%
Epoch 33/100, Train Loss: 0.337088, Train Acc: 88.45%, Val Loss: 0.539040, Val Acc: 82.38%
Epoch 34/100, Train Loss: 0.327353, Train Acc: 88.62%, Val Loss: 0.511431, Val Acc: 83.05%
Epoch 35/100, Train Loss: 0.321513, Train Acc: 89.21%, Val Loss: 0.486687, Val Acc: 83.78%
Epoch 36/100, Train Loss: 0.312899, Train Acc: 89.37%, Val Loss: 0.504892, Val Acc: 83.32%
Epoch 37/100, Train Loss: 0.302021, Train Acc: 89.72%, Val Loss: 0.520303, Val Acc: 83.50%
Epoch 38/100, Train Loss: 0.296897, Train Acc: 89.74%, Val Loss: 0.544041, Val Acc: 83.10%
Epoch 39/100, Train Loss: 0.294059, Train Acc: 90.06%, Val Loss: 0.539777, Val Acc: 83.30%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8336}]
Valore m[value]:  0.8336
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  1
DEVO RIMUOVERE:  {'index': '1', 'type': 'Sequential', 'layers': [{'index': '1.0', 'type': 'Conv2d', 'args': {'in_channels': 32, 'out_channels': 32, 'kernel_size': (3, 3), 'stride': (2, 2), 'padding': (1, 1), 'dilation': (1, 1), 'groups': 1, 'padding_mode': 'zeros'}}, {'index': '1.1', 'type': 'BatchNorm2d', 'args': {'num_features': 32, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}}, {'index': '1.2', 'type': 'ReLU', 'args': {'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5}, {'op': 'reduce_depth', 'val': 1}]
Reduction ratio: 1.0
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (16): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (18): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
  )
  (19): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
  )
  (18): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.626992, Train Acc: 39.18%, Val Loss: 1.278817, Val Acc: 53.01%
Epoch 2/100, Train Loss: 1.206640, Train Acc: 56.90%, Val Loss: 1.135116, Val Acc: 60.04%
Epoch 3/100, Train Loss: 0.981930, Train Acc: 65.12%, Val Loss: 0.983073, Val Acc: 66.10%
Epoch 4/100, Train Loss: 0.835001, Train Acc: 70.89%, Val Loss: 0.848574, Val Acc: 70.62%
Epoch 5/100, Train Loss: 0.736077, Train Acc: 74.54%, Val Loss: 0.711755, Val Acc: 75.16%
Epoch 6/100, Train Loss: 0.667766, Train Acc: 77.21%, Val Loss: 0.787325, Val Acc: 72.86%
Epoch 7/100, Train Loss: 0.602031, Train Acc: 79.36%, Val Loss: 0.615908, Val Acc: 78.64%
Epoch 8/100, Train Loss: 0.555372, Train Acc: 81.04%, Val Loss: 0.603739, Val Acc: 79.93%
Epoch 9/100, Train Loss: 0.519711, Train Acc: 82.23%, Val Loss: 0.587921, Val Acc: 80.45%
Epoch 10/100, Train Loss: 0.484679, Train Acc: 83.57%, Val Loss: 0.528275, Val Acc: 82.30%
Epoch 11/100, Train Loss: 0.451601, Train Acc: 84.42%, Val Loss: 0.509964, Val Acc: 82.75%
Epoch 12/100, Train Loss: 0.426377, Train Acc: 85.32%, Val Loss: 0.489122, Val Acc: 82.61%
Epoch 13/100, Train Loss: 0.399349, Train Acc: 86.42%, Val Loss: 0.484747, Val Acc: 83.46%
Epoch 14/100, Train Loss: 0.379064, Train Acc: 87.21%, Val Loss: 0.483039, Val Acc: 83.98%
Epoch 15/100, Train Loss: 0.360517, Train Acc: 87.69%, Val Loss: 0.473034, Val Acc: 84.13%
Epoch 16/100, Train Loss: 0.336744, Train Acc: 88.49%, Val Loss: 0.468184, Val Acc: 84.21%
Epoch 17/100, Train Loss: 0.319991, Train Acc: 89.16%, Val Loss: 0.456592, Val Acc: 85.30%
Epoch 18/100, Train Loss: 0.307588, Train Acc: 89.50%, Val Loss: 0.461363, Val Acc: 84.79%
Epoch 19/100, Train Loss: 0.289082, Train Acc: 90.12%, Val Loss: 0.440349, Val Acc: 85.59%
Epoch 20/100, Train Loss: 0.277441, Train Acc: 90.34%, Val Loss: 0.445581, Val Acc: 85.81%
Epoch 21/100, Train Loss: 0.262940, Train Acc: 90.98%, Val Loss: 0.411258, Val Acc: 86.64%
Epoch 22/100, Train Loss: 0.249563, Train Acc: 91.60%, Val Loss: 0.420848, Val Acc: 86.79%
Epoch 23/100, Train Loss: 0.238415, Train Acc: 91.91%, Val Loss: 0.441290, Val Acc: 86.36%
Epoch 24/100, Train Loss: 0.224780, Train Acc: 92.28%, Val Loss: 0.447904, Val Acc: 85.75%
Epoch 25/100, Train Loss: 0.217841, Train Acc: 92.53%, Val Loss: 0.434856, Val Acc: 86.42%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8696}]
Valore m[value]:  0.8696
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  17
DEVO RIMUOVERE:  {'index': '17', 'type': 'Sequential', 'layers': [{'index': '17.0', 'type': 'Linear', 'args': {'in_features': 2048, 'out_features': 2048}}, {'index': '17.1', 'type': 'ReLU', 'args': {'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17}]
Reduction ratio: 0.95
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
  )
  (18): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.674254, Train Acc: 37.73%, Val Loss: 1.304815, Val Acc: 51.49%
Epoch 2/100, Train Loss: 1.253601, Train Acc: 55.12%, Val Loss: 1.181844, Val Acc: 59.41%
Epoch 3/100, Train Loss: 1.039480, Train Acc: 63.25%, Val Loss: 0.959107, Val Acc: 66.79%
Epoch 4/100, Train Loss: 0.893426, Train Acc: 68.97%, Val Loss: 0.847161, Val Acc: 70.12%
Epoch 5/100, Train Loss: 0.780972, Train Acc: 72.71%, Val Loss: 0.785592, Val Acc: 73.68%
Epoch 6/100, Train Loss: 0.702362, Train Acc: 75.74%, Val Loss: 0.787486, Val Acc: 73.91%
Epoch 7/100, Train Loss: 0.643001, Train Acc: 77.90%, Val Loss: 0.655871, Val Acc: 77.79%
Epoch 8/100, Train Loss: 0.586480, Train Acc: 80.00%, Val Loss: 0.646544, Val Acc: 78.49%
Epoch 9/100, Train Loss: 0.544229, Train Acc: 81.33%, Val Loss: 0.602768, Val Acc: 79.83%
Epoch 10/100, Train Loss: 0.505160, Train Acc: 82.64%, Val Loss: 0.647001, Val Acc: 78.48%
Epoch 11/100, Train Loss: 0.478196, Train Acc: 83.84%, Val Loss: 0.542705, Val Acc: 82.01%
Epoch 12/100, Train Loss: 0.448922, Train Acc: 84.48%, Val Loss: 0.588291, Val Acc: 80.58%
Epoch 13/100, Train Loss: 0.422701, Train Acc: 85.53%, Val Loss: 0.529474, Val Acc: 82.94%
Epoch 14/100, Train Loss: 0.396771, Train Acc: 86.33%, Val Loss: 0.503360, Val Acc: 83.10%
Epoch 15/100, Train Loss: 0.373612, Train Acc: 87.23%, Val Loss: 0.514817, Val Acc: 83.76%
Epoch 16/100, Train Loss: 0.354627, Train Acc: 87.74%, Val Loss: 0.479364, Val Acc: 84.69%
Epoch 17/100, Train Loss: 0.336251, Train Acc: 88.47%, Val Loss: 0.527458, Val Acc: 82.78%
Epoch 18/100, Train Loss: 0.321938, Train Acc: 88.91%, Val Loss: 0.545588, Val Acc: 82.70%
Epoch 19/100, Train Loss: 0.303287, Train Acc: 89.52%, Val Loss: 0.495126, Val Acc: 84.52%
Epoch 20/100, Train Loss: 0.289491, Train Acc: 90.02%, Val Loss: 0.497694, Val Acc: 84.82%
Epoch 21/100, Train Loss: 0.277731, Train Acc: 90.52%, Val Loss: 0.471312, Val Acc: 85.11%
Epoch 22/100, Train Loss: 0.261706, Train Acc: 91.02%, Val Loss: 0.440183, Val Acc: 86.27%
Epoch 23/100, Train Loss: 0.246990, Train Acc: 91.52%, Val Loss: 0.477826, Val Acc: 85.60%
Epoch 24/100, Train Loss: 0.239612, Train Acc: 91.73%, Val Loss: 0.471833, Val Acc: 85.92%
Epoch 25/100, Train Loss: 0.227243, Train Acc: 92.32%, Val Loss: 0.494793, Val Acc: 85.62%
Epoch 26/100, Train Loss: 0.221757, Train Acc: 92.40%, Val Loss: 0.415413, Val Acc: 87.23%
Epoch 27/100, Train Loss: 0.208662, Train Acc: 92.78%, Val Loss: 0.505852, Val Acc: 85.16%
Epoch 28/100, Train Loss: 0.199473, Train Acc: 93.04%, Val Loss: 0.508836, Val Acc: 86.38%
Epoch 29/100, Train Loss: 0.192448, Train Acc: 93.28%, Val Loss: 0.452940, Val Acc: 87.64%
Epoch 30/100, Train Loss: 0.179536, Train Acc: 93.71%, Val Loss: 0.446492, Val Acc: 87.58%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8578}]
Valore m[value]:  0.8578
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  1
DEVO RIMUOVERE:  {'index': '1', 'type': 'Sequential', 'layers': [{'index': '1.0', 'type': 'Conv2d', 'args': {'in_channels': 32, 'out_channels': 64, 'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': 1, 'padding_mode': 'zeros'}}, {'index': '1.1', 'type': 'BatchNorm2d', 'args': {'num_features': 64, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}}, {'index': '1.2', 'type': 'ReLU', 'args': {'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1}]
Reduction ratio: 0.9
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (15): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (17): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.671061, Train Acc: 38.02%, Val Loss: 1.333336, Val Acc: 50.36%
Epoch 2/100, Train Loss: 1.274272, Train Acc: 54.04%, Val Loss: 1.116507, Val Acc: 60.33%
Epoch 3/100, Train Loss: 1.058302, Train Acc: 62.42%, Val Loss: 0.976491, Val Acc: 65.27%
Epoch 4/100, Train Loss: 0.902959, Train Acc: 68.41%, Val Loss: 0.892533, Val Acc: 68.88%
Epoch 5/100, Train Loss: 0.789864, Train Acc: 72.72%, Val Loss: 0.776515, Val Acc: 73.57%
Epoch 6/100, Train Loss: 0.699842, Train Acc: 75.70%, Val Loss: 0.810455, Val Acc: 72.82%
Epoch 7/100, Train Loss: 0.645840, Train Acc: 77.91%, Val Loss: 0.621417, Val Acc: 78.92%
Epoch 8/100, Train Loss: 0.591012, Train Acc: 79.78%, Val Loss: 0.700033, Val Acc: 77.11%
Epoch 9/100, Train Loss: 0.548927, Train Acc: 81.33%, Val Loss: 0.581694, Val Acc: 80.29%
Epoch 10/100, Train Loss: 0.512647, Train Acc: 82.71%, Val Loss: 0.555787, Val Acc: 81.49%
Epoch 11/100, Train Loss: 0.483192, Train Acc: 83.38%, Val Loss: 0.582773, Val Acc: 81.36%
Epoch 12/100, Train Loss: 0.453972, Train Acc: 84.46%, Val Loss: 0.561058, Val Acc: 81.68%
Epoch 13/100, Train Loss: 0.423348, Train Acc: 85.39%, Val Loss: 0.513478, Val Acc: 82.96%
Epoch 14/100, Train Loss: 0.406213, Train Acc: 86.04%, Val Loss: 0.499389, Val Acc: 83.16%
Epoch 15/100, Train Loss: 0.381867, Train Acc: 86.79%, Val Loss: 0.529266, Val Acc: 82.83%
Epoch 16/100, Train Loss: 0.363333, Train Acc: 87.63%, Val Loss: 0.499958, Val Acc: 83.67%
Epoch 17/100, Train Loss: 0.338936, Train Acc: 88.32%, Val Loss: 0.479103, Val Acc: 84.60%
Epoch 18/100, Train Loss: 0.329921, Train Acc: 88.68%, Val Loss: 0.483467, Val Acc: 84.32%
Epoch 19/100, Train Loss: 0.312109, Train Acc: 89.32%, Val Loss: 0.495001, Val Acc: 83.90%
Epoch 20/100, Train Loss: 0.296289, Train Acc: 89.85%, Val Loss: 0.457759, Val Acc: 85.67%
Epoch 21/100, Train Loss: 0.280677, Train Acc: 90.40%, Val Loss: 0.481704, Val Acc: 84.75%
Epoch 22/100, Train Loss: 0.269285, Train Acc: 90.73%, Val Loss: 0.431136, Val Acc: 86.51%
Epoch 23/100, Train Loss: 0.258568, Train Acc: 91.02%, Val Loss: 0.443388, Val Acc: 85.91%
Epoch 24/100, Train Loss: 0.243105, Train Acc: 91.75%, Val Loss: 0.442173, Val Acc: 86.20%
Epoch 25/100, Train Loss: 0.236255, Train Acc: 91.86%, Val Loss: 0.480746, Val Acc: 85.34%
Epoch 26/100, Train Loss: 0.226033, Train Acc: 92.13%, Val Loss: 0.445570, Val Acc: 86.03%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8626}]
Valore m[value]:  0.8626
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 128 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 0.85
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=12544, out_features=2048, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=2048, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=6272, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=1024, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.769528, Train Acc: 32.77%, Val Loss: 1.474237, Val Acc: 44.85%
Epoch 2/100, Train Loss: 1.443034, Train Acc: 46.70%, Val Loss: 1.312557, Val Acc: 51.77%
Epoch 3/100, Train Loss: 1.285661, Train Acc: 53.61%, Val Loss: 1.177350, Val Acc: 57.01%
Epoch 4/100, Train Loss: 1.165906, Train Acc: 58.26%, Val Loss: 1.064530, Val Acc: 61.66%
Epoch 5/100, Train Loss: 1.078500, Train Acc: 61.50%, Val Loss: 1.011356, Val Acc: 64.28%
Epoch 6/100, Train Loss: 1.000143, Train Acc: 64.57%, Val Loss: 0.980032, Val Acc: 65.23%
Epoch 7/100, Train Loss: 0.933010, Train Acc: 67.17%, Val Loss: 0.910103, Val Acc: 68.04%
Epoch 8/100, Train Loss: 0.872459, Train Acc: 69.41%, Val Loss: 0.818021, Val Acc: 71.34%
Epoch 9/100, Train Loss: 0.824426, Train Acc: 70.99%, Val Loss: 0.818942, Val Acc: 71.48%
Epoch 10/100, Train Loss: 0.772836, Train Acc: 73.05%, Val Loss: 0.832724, Val Acc: 71.15%
Epoch 11/100, Train Loss: 0.731252, Train Acc: 74.52%, Val Loss: 0.748667, Val Acc: 74.25%
Epoch 12/100, Train Loss: 0.692890, Train Acc: 75.83%, Val Loss: 0.737472, Val Acc: 74.18%
Epoch 13/100, Train Loss: 0.661900, Train Acc: 77.04%, Val Loss: 0.675628, Val Acc: 76.41%
Epoch 14/100, Train Loss: 0.630737, Train Acc: 78.03%, Val Loss: 0.679734, Val Acc: 77.19%
Epoch 15/100, Train Loss: 0.600992, Train Acc: 79.12%, Val Loss: 0.633785, Val Acc: 77.74%
Epoch 16/100, Train Loss: 0.574002, Train Acc: 79.94%, Val Loss: 0.611221, Val Acc: 78.83%
Epoch 17/100, Train Loss: 0.552763, Train Acc: 80.79%, Val Loss: 0.595875, Val Acc: 79.25%
Epoch 18/100, Train Loss: 0.539309, Train Acc: 81.54%, Val Loss: 0.606441, Val Acc: 79.19%
Epoch 19/100, Train Loss: 0.514368, Train Acc: 82.03%, Val Loss: 0.593372, Val Acc: 79.83%
Epoch 20/100, Train Loss: 0.496635, Train Acc: 82.73%, Val Loss: 0.610195, Val Acc: 79.67%
Epoch 21/100, Train Loss: 0.477923, Train Acc: 83.52%, Val Loss: 0.581588, Val Acc: 80.26%
Epoch 22/100, Train Loss: 0.466372, Train Acc: 83.57%, Val Loss: 0.582946, Val Acc: 80.89%
Epoch 23/100, Train Loss: 0.452339, Train Acc: 84.45%, Val Loss: 0.579434, Val Acc: 81.17%
Epoch 24/100, Train Loss: 0.441185, Train Acc: 84.70%, Val Loss: 0.545863, Val Acc: 81.91%
Epoch 25/100, Train Loss: 0.420334, Train Acc: 85.48%, Val Loss: 0.562112, Val Acc: 81.65%
Epoch 26/100, Train Loss: 0.408959, Train Acc: 85.63%, Val Loss: 0.569689, Val Acc: 81.52%
Epoch 27/100, Train Loss: 0.397359, Train Acc: 86.12%, Val Loss: 0.584642, Val Acc: 81.51%
Epoch 28/100, Train Loss: 0.385850, Train Acc: 86.45%, Val Loss: 0.550133, Val Acc: 81.92%
Epoch 29/100, Train Loss: 0.376973, Train Acc: 86.85%, Val Loss: 0.544093, Val Acc: 82.66%
Epoch 30/100, Train Loss: 0.364274, Train Acc: 87.20%, Val Loss: 0.546433, Val Acc: 82.54%
Epoch 31/100, Train Loss: 0.356916, Train Acc: 87.51%, Val Loss: 0.521022, Val Acc: 83.19%
Epoch 32/100, Train Loss: 0.346041, Train Acc: 87.98%, Val Loss: 0.553625, Val Acc: 82.71%
Epoch 33/100, Train Loss: 0.332984, Train Acc: 88.37%, Val Loss: 0.524681, Val Acc: 82.83%
Epoch 34/100, Train Loss: 0.325661, Train Acc: 88.70%, Val Loss: 0.547932, Val Acc: 82.90%
Epoch 35/100, Train Loss: 0.320044, Train Acc: 88.68%, Val Loss: 0.537872, Val Acc: 83.13%
Epoch 36/100, Train Loss: 0.304788, Train Acc: 89.37%, Val Loss: 0.502465, Val Acc: 83.78%
Epoch 37/100, Train Loss: 0.301255, Train Acc: 89.38%, Val Loss: 0.550814, Val Acc: 83.52%
Epoch 38/100, Train Loss: 0.292991, Train Acc: 89.65%, Val Loss: 0.519964, Val Acc: 83.46%
Epoch 39/100, Train Loss: 0.287016, Train Acc: 89.99%, Val Loss: 0.539484, Val Acc: 83.13%
Epoch 40/100, Train Loss: 0.280954, Train Acc: 90.04%, Val Loss: 0.504637, Val Acc: 84.51%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8378}]
Valore m[value]:  0.8378
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  15
DEVO RIMUOVERE:  {'index': '15', 'type': 'Sequential', 'layers': [{'index': '15.0', 'type': 'Linear', 'args': {'in_features': 6272, 'out_features': 1024}}, {'index': '15.1', 'type': 'ReLU', 'args': {'inplace': False}}, {'index': '15.2', 'type': 'Dropout', 'args': {'p': 0.5, 'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15}]
Reduction ratio: 0.85
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=6272, out_features=1024, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
  )
  (16): Sequential(
    (0): Linear(in_features=1024, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=6272, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.855313, Train Acc: 30.55%, Val Loss: 1.558345, Val Acc: 42.36%
Epoch 2/100, Train Loss: 1.512333, Train Acc: 44.21%, Val Loss: 1.336276, Val Acc: 50.24%
Epoch 3/100, Train Loss: 1.338707, Train Acc: 51.43%, Val Loss: 1.221271, Val Acc: 55.73%
Epoch 4/100, Train Loss: 1.209148, Train Acc: 56.18%, Val Loss: 1.147289, Val Acc: 59.44%
Epoch 5/100, Train Loss: 1.106858, Train Acc: 60.34%, Val Loss: 1.055520, Val Acc: 62.68%
Epoch 6/100, Train Loss: 1.025721, Train Acc: 63.47%, Val Loss: 0.967944, Val Acc: 65.65%
Epoch 7/100, Train Loss: 0.955055, Train Acc: 66.07%, Val Loss: 0.909238, Val Acc: 67.83%
Epoch 8/100, Train Loss: 0.895399, Train Acc: 68.00%, Val Loss: 0.871466, Val Acc: 69.15%
Epoch 9/100, Train Loss: 0.837580, Train Acc: 70.42%, Val Loss: 0.815096, Val Acc: 71.42%
Epoch 10/100, Train Loss: 0.788802, Train Acc: 72.13%, Val Loss: 0.775671, Val Acc: 73.28%
Epoch 11/100, Train Loss: 0.743074, Train Acc: 73.95%, Val Loss: 0.801091, Val Acc: 72.59%
Epoch 12/100, Train Loss: 0.703326, Train Acc: 75.26%, Val Loss: 0.711713, Val Acc: 74.75%
Epoch 13/100, Train Loss: 0.668959, Train Acc: 76.51%, Val Loss: 0.746929, Val Acc: 74.14%
Epoch 14/100, Train Loss: 0.640324, Train Acc: 77.68%, Val Loss: 0.691264, Val Acc: 75.82%
Epoch 15/100, Train Loss: 0.606984, Train Acc: 78.69%, Val Loss: 0.669779, Val Acc: 77.25%
Epoch 16/100, Train Loss: 0.594744, Train Acc: 79.19%, Val Loss: 0.631670, Val Acc: 78.61%
Epoch 17/100, Train Loss: 0.563103, Train Acc: 80.07%, Val Loss: 0.627520, Val Acc: 78.62%
Epoch 18/100, Train Loss: 0.538611, Train Acc: 81.14%, Val Loss: 0.597301, Val Acc: 79.46%
Epoch 19/100, Train Loss: 0.518251, Train Acc: 82.02%, Val Loss: 0.584893, Val Acc: 79.70%
Epoch 20/100, Train Loss: 0.505022, Train Acc: 82.35%, Val Loss: 0.599595, Val Acc: 79.86%
Epoch 21/100, Train Loss: 0.487971, Train Acc: 82.83%, Val Loss: 0.658767, Val Acc: 78.06%
Epoch 22/100, Train Loss: 0.471464, Train Acc: 83.45%, Val Loss: 0.563731, Val Acc: 81.32%
Epoch 23/100, Train Loss: 0.452326, Train Acc: 84.03%, Val Loss: 0.545921, Val Acc: 81.93%
Epoch 24/100, Train Loss: 0.436293, Train Acc: 84.58%, Val Loss: 0.563738, Val Acc: 81.61%
Epoch 25/100, Train Loss: 0.429565, Train Acc: 85.06%, Val Loss: 0.590002, Val Acc: 80.22%
Epoch 26/100, Train Loss: 0.415889, Train Acc: 85.32%, Val Loss: 0.576886, Val Acc: 81.39%
Epoch 27/100, Train Loss: 0.402221, Train Acc: 85.79%, Val Loss: 0.533704, Val Acc: 82.55%
Epoch 28/100, Train Loss: 0.386668, Train Acc: 86.44%, Val Loss: 0.504659, Val Acc: 83.38%
Epoch 29/100, Train Loss: 0.377820, Train Acc: 86.66%, Val Loss: 0.546074, Val Acc: 81.91%
Epoch 30/100, Train Loss: 0.368263, Train Acc: 87.04%, Val Loss: 0.554273, Val Acc: 82.41%
Epoch 31/100, Train Loss: 0.356924, Train Acc: 87.43%, Val Loss: 0.508202, Val Acc: 83.61%
Epoch 32/100, Train Loss: 0.348043, Train Acc: 87.77%, Val Loss: 0.574696, Val Acc: 82.18%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.8322}]
Valore m[value]:  0.8322
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 64 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 0.8
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=6272, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=3136, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.007264, Train Acc: 23.78%, Val Loss: 1.748582, Val Acc: 35.20%
Epoch 2/100, Train Loss: 1.708287, Train Acc: 35.49%, Val Loss: 1.577513, Val Acc: 41.04%
Epoch 3/100, Train Loss: 1.582889, Train Acc: 41.42%, Val Loss: 1.461756, Val Acc: 46.14%
Epoch 4/100, Train Loss: 1.483400, Train Acc: 45.44%, Val Loss: 1.389915, Val Acc: 49.38%
Epoch 5/100, Train Loss: 1.403248, Train Acc: 48.99%, Val Loss: 1.294049, Val Acc: 52.63%
Epoch 6/100, Train Loss: 1.322084, Train Acc: 52.15%, Val Loss: 1.225258, Val Acc: 55.73%
Epoch 7/100, Train Loss: 1.263804, Train Acc: 54.48%, Val Loss: 1.186025, Val Acc: 57.27%
Epoch 8/100, Train Loss: 1.217874, Train Acc: 56.19%, Val Loss: 1.144087, Val Acc: 58.58%
Epoch 9/100, Train Loss: 1.171095, Train Acc: 58.17%, Val Loss: 1.106582, Val Acc: 60.22%
Epoch 10/100, Train Loss: 1.119924, Train Acc: 60.00%, Val Loss: 1.090449, Val Acc: 61.29%
Epoch 11/100, Train Loss: 1.082205, Train Acc: 61.24%, Val Loss: 1.030277, Val Acc: 63.35%
Epoch 12/100, Train Loss: 1.046098, Train Acc: 62.67%, Val Loss: 0.997954, Val Acc: 64.52%
Epoch 13/100, Train Loss: 1.015062, Train Acc: 63.79%, Val Loss: 0.976907, Val Acc: 65.23%
Epoch 14/100, Train Loss: 0.984184, Train Acc: 65.20%, Val Loss: 1.011599, Val Acc: 64.54%
Epoch 15/100, Train Loss: 0.951044, Train Acc: 66.23%, Val Loss: 0.928612, Val Acc: 66.87%
Epoch 16/100, Train Loss: 0.930289, Train Acc: 67.11%, Val Loss: 0.910567, Val Acc: 67.58%
Epoch 17/100, Train Loss: 0.905987, Train Acc: 67.80%, Val Loss: 0.881587, Val Acc: 68.90%
Epoch 18/100, Train Loss: 0.875611, Train Acc: 69.00%, Val Loss: 0.876189, Val Acc: 69.29%
Epoch 19/100, Train Loss: 0.853766, Train Acc: 69.80%, Val Loss: 0.850192, Val Acc: 69.93%
Epoch 20/100, Train Loss: 0.837400, Train Acc: 70.41%, Val Loss: 0.846675, Val Acc: 70.00%
Epoch 21/100, Train Loss: 0.810316, Train Acc: 71.37%, Val Loss: 0.801787, Val Acc: 72.73%
Epoch 22/100, Train Loss: 0.796376, Train Acc: 71.93%, Val Loss: 0.799905, Val Acc: 72.14%
Epoch 23/100, Train Loss: 0.774833, Train Acc: 73.00%, Val Loss: 0.778835, Val Acc: 72.63%
Epoch 24/100, Train Loss: 0.756813, Train Acc: 73.48%, Val Loss: 0.799878, Val Acc: 72.36%
Epoch 25/100, Train Loss: 0.740529, Train Acc: 74.05%, Val Loss: 0.762731, Val Acc: 73.12%
Epoch 26/100, Train Loss: 0.724152, Train Acc: 74.38%, Val Loss: 0.750169, Val Acc: 74.26%
Epoch 27/100, Train Loss: 0.713528, Train Acc: 75.01%, Val Loss: 0.753236, Val Acc: 73.64%
Epoch 28/100, Train Loss: 0.700805, Train Acc: 75.46%, Val Loss: 0.728781, Val Acc: 75.03%
Epoch 29/100, Train Loss: 0.689512, Train Acc: 75.72%, Val Loss: 0.723057, Val Acc: 75.10%
Epoch 30/100, Train Loss: 0.674324, Train Acc: 76.41%, Val Loss: 0.707255, Val Acc: 75.66%
Epoch 31/100, Train Loss: 0.663404, Train Acc: 76.47%, Val Loss: 0.703142, Val Acc: 75.48%
Epoch 32/100, Train Loss: 0.648056, Train Acc: 77.35%, Val Loss: 0.714457, Val Acc: 75.17%
Epoch 33/100, Train Loss: 0.642527, Train Acc: 77.46%, Val Loss: 0.690606, Val Acc: 76.09%
Epoch 34/100, Train Loss: 0.623444, Train Acc: 78.05%, Val Loss: 0.700940, Val Acc: 75.92%
Epoch 35/100, Train Loss: 0.623691, Train Acc: 78.05%, Val Loss: 0.688920, Val Acc: 76.43%
Epoch 36/100, Train Loss: 0.605212, Train Acc: 78.72%, Val Loss: 0.682247, Val Acc: 76.62%
Epoch 37/100, Train Loss: 0.599374, Train Acc: 78.87%, Val Loss: 0.674816, Val Acc: 76.51%
Epoch 38/100, Train Loss: 0.590470, Train Acc: 79.37%, Val Loss: 0.662689, Val Acc: 77.40%
Epoch 39/100, Train Loss: 0.585246, Train Acc: 79.36%, Val Loss: 0.657452, Val Acc: 77.34%
Epoch 40/100, Train Loss: 0.576010, Train Acc: 79.76%, Val Loss: 0.646997, Val Acc: 77.56%
Epoch 41/100, Train Loss: 0.568565, Train Acc: 80.04%, Val Loss: 0.650077, Val Acc: 77.90%
Epoch 42/100, Train Loss: 0.555763, Train Acc: 80.39%, Val Loss: 0.636858, Val Acc: 78.20%
Epoch 43/100, Train Loss: 0.554028, Train Acc: 80.64%, Val Loss: 0.625847, Val Acc: 78.43%
Epoch 44/100, Train Loss: 0.545581, Train Acc: 80.95%, Val Loss: 0.646821, Val Acc: 78.12%
Epoch 45/100, Train Loss: 0.538372, Train Acc: 81.10%, Val Loss: 0.630297, Val Acc: 78.71%
Epoch 46/100, Train Loss: 0.530663, Train Acc: 81.38%, Val Loss: 0.630950, Val Acc: 78.95%
Epoch 47/100, Train Loss: 0.524605, Train Acc: 81.69%, Val Loss: 0.634619, Val Acc: 78.67%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7843}]
Valore m[value]:  0.7843
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  1
DEVO RIMUOVERE:  {'index': '1', 'type': 'Sequential', 'layers': [{'index': '1.0', 'type': 'Conv2d', 'args': {'in_channels': 8, 'out_channels': 16, 'kernel_size': (3, 3), 'stride': (2, 2), 'padding': (1, 1), 'dilation': (1, 1), 'groups': 1, 'padding_mode': 'zeros'}}, {'index': '1.1', 'type': 'BatchNorm2d', 'args': {'num_features': 16, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}}, {'index': '1.2', 'type': 'ReLU', 'args': {'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1}]
Reduction ratio: 0.8
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (14): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (15): Sequential(
    (0): Linear(in_features=3136, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (14): Sequential(
    (0): Linear(in_features=3136, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 1.893231, Train Acc: 29.65%, Val Loss: 1.527363, Val Acc: 43.80%
Epoch 2/100, Train Loss: 1.530962, Train Acc: 43.70%, Val Loss: 1.339794, Val Acc: 51.27%
Epoch 3/100, Train Loss: 1.361651, Train Acc: 50.53%, Val Loss: 1.241750, Val Acc: 55.53%
Epoch 4/100, Train Loss: 1.244045, Train Acc: 55.21%, Val Loss: 1.172029, Val Acc: 58.03%
Epoch 5/100, Train Loss: 1.140957, Train Acc: 59.21%, Val Loss: 1.153129, Val Acc: 59.59%
Epoch 6/100, Train Loss: 1.053719, Train Acc: 62.44%, Val Loss: 0.982696, Val Acc: 65.06%
Epoch 7/100, Train Loss: 0.991786, Train Acc: 64.43%, Val Loss: 0.920802, Val Acc: 67.50%
Epoch 8/100, Train Loss: 0.924487, Train Acc: 67.38%, Val Loss: 0.875390, Val Acc: 69.14%
Epoch 9/100, Train Loss: 0.870112, Train Acc: 69.28%, Val Loss: 0.850037, Val Acc: 70.41%
Epoch 10/100, Train Loss: 0.826115, Train Acc: 70.94%, Val Loss: 0.819876, Val Acc: 71.71%
Epoch 11/100, Train Loss: 0.776772, Train Acc: 72.87%, Val Loss: 0.750550, Val Acc: 74.19%
Epoch 12/100, Train Loss: 0.742494, Train Acc: 74.03%, Val Loss: 0.737480, Val Acc: 74.42%
Epoch 13/100, Train Loss: 0.704200, Train Acc: 75.24%, Val Loss: 0.756052, Val Acc: 74.42%
Epoch 14/100, Train Loss: 0.679126, Train Acc: 76.34%, Val Loss: 0.695286, Val Acc: 76.69%
Epoch 15/100, Train Loss: 0.650559, Train Acc: 77.36%, Val Loss: 0.709753, Val Acc: 76.13%
Epoch 16/100, Train Loss: 0.626321, Train Acc: 78.46%, Val Loss: 0.655312, Val Acc: 77.77%
Epoch 17/100, Train Loss: 0.607904, Train Acc: 78.87%, Val Loss: 0.672989, Val Acc: 77.68%
Epoch 18/100, Train Loss: 0.586609, Train Acc: 79.52%, Val Loss: 0.619446, Val Acc: 79.23%
Epoch 19/100, Train Loss: 0.563007, Train Acc: 80.27%, Val Loss: 0.613284, Val Acc: 79.41%
Epoch 20/100, Train Loss: 0.552398, Train Acc: 80.52%, Val Loss: 0.629006, Val Acc: 79.08%
Epoch 21/100, Train Loss: 0.532300, Train Acc: 81.47%, Val Loss: 0.583141, Val Acc: 80.43%
Epoch 22/100, Train Loss: 0.514670, Train Acc: 81.98%, Val Loss: 0.625316, Val Acc: 78.78%
Epoch 23/100, Train Loss: 0.505507, Train Acc: 82.36%, Val Loss: 0.594398, Val Acc: 80.56%
Epoch 24/100, Train Loss: 0.486887, Train Acc: 82.99%, Val Loss: 0.554831, Val Acc: 81.37%
Epoch 25/100, Train Loss: 0.474058, Train Acc: 83.60%, Val Loss: 0.571075, Val Acc: 81.20%
Epoch 26/100, Train Loss: 0.466140, Train Acc: 83.78%, Val Loss: 0.549914, Val Acc: 81.83%
Epoch 27/100, Train Loss: 0.454815, Train Acc: 84.08%, Val Loss: 0.539968, Val Acc: 82.20%
Epoch 28/100, Train Loss: 0.445443, Train Acc: 84.39%, Val Loss: 0.562796, Val Acc: 81.72%
Epoch 29/100, Train Loss: 0.432400, Train Acc: 84.96%, Val Loss: 0.552684, Val Acc: 82.77%
Epoch 30/100, Train Loss: 0.424335, Train Acc: 85.14%, Val Loss: 0.556151, Val Acc: 81.90%
Epoch 31/100, Train Loss: 0.413998, Train Acc: 85.45%, Val Loss: 0.545854, Val Acc: 82.02%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.822}]
Valore m[value]:  0.822
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 4 feature
Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 32 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 0.75
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (14): Sequential(
    (0): Linear(in_features=3136, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (14): Sequential(
    (0): Linear(in_features=1568, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.026065, Train Acc: 23.77%, Val Loss: 1.717356, Val Acc: 37.25%
Epoch 2/100, Train Loss: 1.709129, Train Acc: 36.24%, Val Loss: 1.573966, Val Acc: 42.65%
Epoch 3/100, Train Loss: 1.586406, Train Acc: 41.10%, Val Loss: 1.445241, Val Acc: 47.15%
Epoch 4/100, Train Loss: 1.501410, Train Acc: 44.59%, Val Loss: 1.393541, Val Acc: 48.57%
Epoch 5/100, Train Loss: 1.437943, Train Acc: 47.49%, Val Loss: 1.328934, Val Acc: 52.48%
Epoch 6/100, Train Loss: 1.379045, Train Acc: 49.64%, Val Loss: 1.278772, Val Acc: 53.65%
Epoch 7/100, Train Loss: 1.324481, Train Acc: 51.79%, Val Loss: 1.233654, Val Acc: 55.57%
Epoch 8/100, Train Loss: 1.276591, Train Acc: 53.62%, Val Loss: 1.196387, Val Acc: 56.51%
Epoch 9/100, Train Loss: 1.229454, Train Acc: 55.62%, Val Loss: 1.165507, Val Acc: 57.55%
Epoch 10/100, Train Loss: 1.193846, Train Acc: 56.83%, Val Loss: 1.121801, Val Acc: 59.71%
Epoch 11/100, Train Loss: 1.153339, Train Acc: 58.49%, Val Loss: 1.083919, Val Acc: 60.81%
Epoch 12/100, Train Loss: 1.122884, Train Acc: 59.50%, Val Loss: 1.058739, Val Acc: 61.79%
Epoch 13/100, Train Loss: 1.095668, Train Acc: 60.65%, Val Loss: 1.038124, Val Acc: 63.20%
Epoch 14/100, Train Loss: 1.067843, Train Acc: 61.68%, Val Loss: 1.006358, Val Acc: 64.27%
Epoch 15/100, Train Loss: 1.045942, Train Acc: 62.35%, Val Loss: 0.996255, Val Acc: 64.61%
Epoch 16/100, Train Loss: 1.021332, Train Acc: 63.41%, Val Loss: 1.001205, Val Acc: 64.34%
Epoch 17/100, Train Loss: 1.004394, Train Acc: 64.12%, Val Loss: 0.952676, Val Acc: 66.11%
Epoch 18/100, Train Loss: 0.974966, Train Acc: 65.16%, Val Loss: 0.958016, Val Acc: 66.08%
Epoch 19/100, Train Loss: 0.961761, Train Acc: 65.72%, Val Loss: 0.926712, Val Acc: 67.56%
Epoch 20/100, Train Loss: 0.942524, Train Acc: 66.45%, Val Loss: 0.922774, Val Acc: 67.45%
Epoch 21/100, Train Loss: 0.926997, Train Acc: 67.00%, Val Loss: 0.892515, Val Acc: 68.61%
Epoch 22/100, Train Loss: 0.907774, Train Acc: 67.75%, Val Loss: 0.882729, Val Acc: 68.85%
Epoch 23/100, Train Loss: 0.894459, Train Acc: 68.47%, Val Loss: 0.891849, Val Acc: 68.59%
Epoch 24/100, Train Loss: 0.877850, Train Acc: 68.89%, Val Loss: 0.856099, Val Acc: 69.97%
Epoch 25/100, Train Loss: 0.857041, Train Acc: 69.66%, Val Loss: 0.845755, Val Acc: 70.84%
Epoch 26/100, Train Loss: 0.844446, Train Acc: 70.05%, Val Loss: 0.842542, Val Acc: 70.30%
Epoch 27/100, Train Loss: 0.828656, Train Acc: 70.51%, Val Loss: 0.833584, Val Acc: 71.17%
Epoch 28/100, Train Loss: 0.818535, Train Acc: 70.96%, Val Loss: 0.818952, Val Acc: 71.77%
Epoch 29/100, Train Loss: 0.803057, Train Acc: 71.77%, Val Loss: 0.789266, Val Acc: 72.72%
Epoch 30/100, Train Loss: 0.790165, Train Acc: 72.04%, Val Loss: 0.797345, Val Acc: 72.65%
Epoch 31/100, Train Loss: 0.778435, Train Acc: 72.56%, Val Loss: 0.796060, Val Acc: 73.09%
Epoch 32/100, Train Loss: 0.767517, Train Acc: 73.02%, Val Loss: 0.772067, Val Acc: 73.12%
Epoch 33/100, Train Loss: 0.754275, Train Acc: 73.53%, Val Loss: 0.755999, Val Acc: 74.05%
Epoch 34/100, Train Loss: 0.746195, Train Acc: 73.75%, Val Loss: 0.763410, Val Acc: 73.65%
Epoch 35/100, Train Loss: 0.736443, Train Acc: 74.17%, Val Loss: 0.742298, Val Acc: 74.50%
Epoch 36/100, Train Loss: 0.724123, Train Acc: 74.59%, Val Loss: 0.791599, Val Acc: 72.83%
Epoch 37/100, Train Loss: 0.715909, Train Acc: 74.76%, Val Loss: 0.740023, Val Acc: 74.69%
Epoch 38/100, Train Loss: 0.706284, Train Acc: 75.18%, Val Loss: 0.722681, Val Acc: 75.35%
Epoch 39/100, Train Loss: 0.697867, Train Acc: 75.53%, Val Loss: 0.735077, Val Acc: 75.14%
Epoch 40/100, Train Loss: 0.694201, Train Acc: 75.80%, Val Loss: 0.713453, Val Acc: 75.72%
Epoch 41/100, Train Loss: 0.682542, Train Acc: 76.10%, Val Loss: 0.709265, Val Acc: 75.97%
Epoch 42/100, Train Loss: 0.670901, Train Acc: 76.48%, Val Loss: 0.721098, Val Acc: 75.97%
Epoch 43/100, Train Loss: 0.667047, Train Acc: 76.61%, Val Loss: 0.695666, Val Acc: 76.26%
Epoch 44/100, Train Loss: 0.658949, Train Acc: 76.95%, Val Loss: 0.704068, Val Acc: 75.96%
Epoch 45/100, Train Loss: 0.648619, Train Acc: 77.19%, Val Loss: 0.687699, Val Acc: 76.21%
Epoch 46/100, Train Loss: 0.645773, Train Acc: 77.44%, Val Loss: 0.685776, Val Acc: 76.72%
Epoch 47/100, Train Loss: 0.639657, Train Acc: 77.47%, Val Loss: 0.670933, Val Acc: 77.15%
Epoch 48/100, Train Loss: 0.636069, Train Acc: 77.90%, Val Loss: 0.665410, Val Acc: 77.40%
Epoch 49/100, Train Loss: 0.623114, Train Acc: 78.10%, Val Loss: 0.667364, Val Acc: 77.64%
Epoch 50/100, Train Loss: 0.622625, Train Acc: 78.27%, Val Loss: 0.660660, Val Acc: 77.60%
Epoch 51/100, Train Loss: 0.614533, Train Acc: 78.53%, Val Loss: 0.652801, Val Acc: 77.90%
Epoch 52/100, Train Loss: 0.605294, Train Acc: 78.85%, Val Loss: 0.651236, Val Acc: 77.86%
Epoch 53/100, Train Loss: 0.607527, Train Acc: 78.97%, Val Loss: 0.639194, Val Acc: 78.03%
Epoch 54/100, Train Loss: 0.598848, Train Acc: 79.02%, Val Loss: 0.635916, Val Acc: 78.91%
Epoch 55/100, Train Loss: 0.594367, Train Acc: 79.25%, Val Loss: 0.649263, Val Acc: 78.04%
Epoch 56/100, Train Loss: 0.585693, Train Acc: 79.37%, Val Loss: 0.641416, Val Acc: 78.44%
Epoch 57/100, Train Loss: 0.583711, Train Acc: 79.74%, Val Loss: 0.643696, Val Acc: 78.17%
Epoch 58/100, Train Loss: 0.579774, Train Acc: 79.82%, Val Loss: 0.643776, Val Acc: 78.44%
Epoch 59/100, Train Loss: 0.577349, Train Acc: 79.74%, Val Loss: 0.617430, Val Acc: 79.46%
Epoch 60/100, Train Loss: 0.572747, Train Acc: 80.02%, Val Loss: 0.618900, Val Acc: 78.96%
Epoch 61/100, Train Loss: 0.567208, Train Acc: 80.35%, Val Loss: 0.616948, Val Acc: 79.12%
Epoch 62/100, Train Loss: 0.564515, Train Acc: 80.44%, Val Loss: 0.633003, Val Acc: 78.45%
Epoch 63/100, Train Loss: 0.560773, Train Acc: 80.58%, Val Loss: 0.643953, Val Acc: 78.72%
Epoch 64/100, Train Loss: 0.559422, Train Acc: 80.42%, Val Loss: 0.596884, Val Acc: 79.72%
Epoch 65/100, Train Loss: 0.548780, Train Acc: 80.66%, Val Loss: 0.608813, Val Acc: 79.36%
Epoch 66/100, Train Loss: 0.548139, Train Acc: 80.80%, Val Loss: 0.613704, Val Acc: 79.47%
Epoch 67/100, Train Loss: 0.540189, Train Acc: 81.27%, Val Loss: 0.619203, Val Acc: 79.36%
Epoch 68/100, Train Loss: 0.541532, Train Acc: 81.06%, Val Loss: 0.598440, Val Acc: 79.63%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7949}]
Valore m[value]:  0.7949
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  12
DEVO RIMUOVERE:  {'index': '12', 'type': 'Sequential', 'layers': [{'index': '12.0', 'type': 'Conv2d', 'args': {'in_channels': 32, 'out_channels': 32, 'kernel_size': (3, 3), 'stride': (2, 2), 'padding': (1, 1), 'dilation': (1, 1), 'groups': 1, 'padding_mode': 'zeros'}}, {'index': '12.1', 'type': 'BatchNorm2d', 'args': {'num_features': 32, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}}, {'index': '12.2', 'type': 'ReLU', 'args': {'inplace': False}}]}
trovato Flatten nel next layer
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 12}]
Reduction ratio: 0.75
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (13): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (14): Sequential(
    (0): Linear(in_features=1568, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (13): Sequential(
    (0): Linear(in_features=1568, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.004785, Train Acc: 24.03%, Val Loss: 1.664296, Val Acc: 37.61%
Epoch 2/100, Train Loss: 1.687932, Train Acc: 36.36%, Val Loss: 1.509286, Val Acc: 43.85%
Epoch 3/100, Train Loss: 1.555215, Train Acc: 42.00%, Val Loss: 1.406338, Val Acc: 48.68%
Epoch 4/100, Train Loss: 1.458333, Train Acc: 46.03%, Val Loss: 1.329503, Val Acc: 51.38%
Epoch 5/100, Train Loss: 1.380518, Train Acc: 49.66%, Val Loss: 1.248169, Val Acc: 54.67%
Epoch 6/100, Train Loss: 1.312519, Train Acc: 52.06%, Val Loss: 1.197735, Val Acc: 56.77%
Epoch 7/100, Train Loss: 1.260728, Train Acc: 54.08%, Val Loss: 1.147341, Val Acc: 58.25%
Epoch 8/100, Train Loss: 1.211279, Train Acc: 56.05%, Val Loss: 1.098276, Val Acc: 60.31%
Epoch 9/100, Train Loss: 1.167321, Train Acc: 57.71%, Val Loss: 1.072464, Val Acc: 61.59%
Epoch 10/100, Train Loss: 1.138318, Train Acc: 59.07%, Val Loss: 1.038490, Val Acc: 62.62%
Epoch 11/100, Train Loss: 1.098011, Train Acc: 60.38%, Val Loss: 1.017522, Val Acc: 63.71%
Epoch 12/100, Train Loss: 1.070027, Train Acc: 61.43%, Val Loss: 0.992229, Val Acc: 64.39%
Epoch 13/100, Train Loss: 1.037410, Train Acc: 62.57%, Val Loss: 1.014084, Val Acc: 64.17%
Epoch 14/100, Train Loss: 1.010162, Train Acc: 63.73%, Val Loss: 0.950598, Val Acc: 65.78%
Epoch 15/100, Train Loss: 0.981442, Train Acc: 64.84%, Val Loss: 0.911441, Val Acc: 67.58%
Epoch 16/100, Train Loss: 0.959327, Train Acc: 65.76%, Val Loss: 0.912918, Val Acc: 67.54%
Epoch 17/100, Train Loss: 0.939933, Train Acc: 66.39%, Val Loss: 0.867027, Val Acc: 69.31%
Epoch 18/100, Train Loss: 0.917212, Train Acc: 67.34%, Val Loss: 0.848123, Val Acc: 70.09%
Epoch 19/100, Train Loss: 0.897321, Train Acc: 67.98%, Val Loss: 0.840669, Val Acc: 70.80%
Epoch 20/100, Train Loss: 0.886473, Train Acc: 68.33%, Val Loss: 0.817870, Val Acc: 71.59%
Epoch 21/100, Train Loss: 0.867763, Train Acc: 69.14%, Val Loss: 0.826812, Val Acc: 71.20%
Epoch 22/100, Train Loss: 0.846768, Train Acc: 69.95%, Val Loss: 0.797028, Val Acc: 72.24%
Epoch 23/100, Train Loss: 0.833196, Train Acc: 70.28%, Val Loss: 0.779966, Val Acc: 72.47%
Epoch 24/100, Train Loss: 0.818863, Train Acc: 70.92%, Val Loss: 0.784648, Val Acc: 72.76%
Epoch 25/100, Train Loss: 0.807799, Train Acc: 71.19%, Val Loss: 0.764451, Val Acc: 73.13%
Epoch 26/100, Train Loss: 0.792482, Train Acc: 71.93%, Val Loss: 0.774972, Val Acc: 73.32%
Epoch 27/100, Train Loss: 0.780017, Train Acc: 72.54%, Val Loss: 0.763056, Val Acc: 73.43%
Epoch 28/100, Train Loss: 0.771555, Train Acc: 72.68%, Val Loss: 0.754808, Val Acc: 73.53%
Epoch 29/100, Train Loss: 0.760594, Train Acc: 73.13%, Val Loss: 0.746682, Val Acc: 74.06%
Epoch 30/100, Train Loss: 0.747119, Train Acc: 73.65%, Val Loss: 0.714000, Val Acc: 75.32%
Epoch 31/100, Train Loss: 0.736146, Train Acc: 73.93%, Val Loss: 0.723276, Val Acc: 75.16%
Epoch 32/100, Train Loss: 0.724613, Train Acc: 74.31%, Val Loss: 0.722531, Val Acc: 75.06%
Epoch 33/100, Train Loss: 0.717914, Train Acc: 74.65%, Val Loss: 0.727808, Val Acc: 75.17%
Epoch 34/100, Train Loss: 0.709836, Train Acc: 74.97%, Val Loss: 0.685286, Val Acc: 76.40%
Epoch 35/100, Train Loss: 0.704250, Train Acc: 75.00%, Val Loss: 0.691994, Val Acc: 76.21%
Epoch 36/100, Train Loss: 0.694932, Train Acc: 75.63%, Val Loss: 0.674800, Val Acc: 76.86%
Epoch 37/100, Train Loss: 0.686778, Train Acc: 75.76%, Val Loss: 0.684904, Val Acc: 76.41%
Epoch 38/100, Train Loss: 0.679404, Train Acc: 75.99%, Val Loss: 0.672384, Val Acc: 76.60%
Epoch 39/100, Train Loss: 0.677619, Train Acc: 76.15%, Val Loss: 0.657306, Val Acc: 77.05%
Epoch 40/100, Train Loss: 0.671741, Train Acc: 76.42%, Val Loss: 0.652814, Val Acc: 77.77%
Epoch 41/100, Train Loss: 0.659334, Train Acc: 76.75%, Val Loss: 0.647700, Val Acc: 77.76%
Epoch 42/100, Train Loss: 0.650069, Train Acc: 77.24%, Val Loss: 0.649150, Val Acc: 78.17%
Epoch 43/100, Train Loss: 0.645991, Train Acc: 77.44%, Val Loss: 0.633030, Val Acc: 78.39%
Epoch 44/100, Train Loss: 0.643470, Train Acc: 77.51%, Val Loss: 0.651008, Val Acc: 77.46%
Epoch 45/100, Train Loss: 0.637555, Train Acc: 77.68%, Val Loss: 0.654453, Val Acc: 77.39%
Epoch 46/100, Train Loss: 0.629682, Train Acc: 77.88%, Val Loss: 0.645421, Val Acc: 77.76%
Epoch 47/100, Train Loss: 0.622511, Train Acc: 78.16%, Val Loss: 0.643700, Val Acc: 78.10%
Epoch 48/100, Train Loss: 0.619224, Train Acc: 78.32%, Val Loss: 0.624298, Val Acc: 79.04%
Epoch 49/100, Train Loss: 0.615013, Train Acc: 78.36%, Val Loss: 0.631128, Val Acc: 78.85%
Epoch 50/100, Train Loss: 0.611956, Train Acc: 78.40%, Val Loss: 0.620038, Val Acc: 78.93%
Epoch 51/100, Train Loss: 0.606733, Train Acc: 78.89%, Val Loss: 0.623442, Val Acc: 78.69%
Epoch 52/100, Train Loss: 0.603645, Train Acc: 78.89%, Val Loss: 0.640505, Val Acc: 78.35%
Epoch 53/100, Train Loss: 0.601603, Train Acc: 79.03%, Val Loss: 0.615513, Val Acc: 78.99%
Epoch 54/100, Train Loss: 0.588091, Train Acc: 79.51%, Val Loss: 0.621724, Val Acc: 78.81%
Epoch 55/100, Train Loss: 0.587301, Train Acc: 79.33%, Val Loss: 0.595788, Val Acc: 79.65%
Epoch 56/100, Train Loss: 0.582642, Train Acc: 79.57%, Val Loss: 0.629938, Val Acc: 78.90%
Epoch 57/100, Train Loss: 0.579340, Train Acc: 79.67%, Val Loss: 0.613539, Val Acc: 79.56%
Epoch 58/100, Train Loss: 0.575505, Train Acc: 79.67%, Val Loss: 0.607507, Val Acc: 79.73%
Epoch 59/100, Train Loss: 0.572722, Train Acc: 79.84%, Val Loss: 0.624678, Val Acc: 79.16%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7958}]
Valore m[value]:  0.7958
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 2 feature
Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 16 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 12},
 {'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 0.7
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (13): Sequential(
    (0): Linear(in_features=1568, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (13): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.191609, Train Acc: 16.86%, Val Loss: 1.955203, Val Acc: 27.78%
Epoch 2/100, Train Loss: 1.925993, Train Acc: 26.93%, Val Loss: 1.763603, Val Acc: 34.63%
Epoch 3/100, Train Loss: 1.801476, Train Acc: 32.13%, Val Loss: 1.660908, Val Acc: 38.21%
Epoch 4/100, Train Loss: 1.731140, Train Acc: 34.72%, Val Loss: 1.605649, Val Acc: 40.74%
Epoch 5/100, Train Loss: 1.679104, Train Acc: 37.02%, Val Loss: 1.561984, Val Acc: 42.78%
Epoch 6/100, Train Loss: 1.640475, Train Acc: 38.86%, Val Loss: 1.521931, Val Acc: 44.47%
Epoch 7/100, Train Loss: 1.600525, Train Acc: 40.58%, Val Loss: 1.480125, Val Acc: 45.60%
Epoch 8/100, Train Loss: 1.566965, Train Acc: 42.11%, Val Loss: 1.444625, Val Acc: 47.26%
Epoch 9/100, Train Loss: 1.532598, Train Acc: 43.64%, Val Loss: 1.412100, Val Acc: 48.89%
Epoch 10/100, Train Loss: 1.503765, Train Acc: 44.93%, Val Loss: 1.385049, Val Acc: 49.53%
Epoch 11/100, Train Loss: 1.477335, Train Acc: 45.88%, Val Loss: 1.361719, Val Acc: 50.53%
Epoch 12/100, Train Loss: 1.455584, Train Acc: 47.00%, Val Loss: 1.344797, Val Acc: 50.90%
Epoch 13/100, Train Loss: 1.433499, Train Acc: 48.10%, Val Loss: 1.326830, Val Acc: 52.14%
Epoch 14/100, Train Loss: 1.416598, Train Acc: 48.74%, Val Loss: 1.308336, Val Acc: 52.57%
Epoch 15/100, Train Loss: 1.398401, Train Acc: 49.55%, Val Loss: 1.308119, Val Acc: 52.39%
Epoch 16/100, Train Loss: 1.381669, Train Acc: 50.13%, Val Loss: 1.285223, Val Acc: 53.71%
Epoch 17/100, Train Loss: 1.364942, Train Acc: 50.70%, Val Loss: 1.269249, Val Acc: 53.97%
Epoch 18/100, Train Loss: 1.353353, Train Acc: 51.24%, Val Loss: 1.252224, Val Acc: 55.15%
Epoch 19/100, Train Loss: 1.338022, Train Acc: 51.92%, Val Loss: 1.233894, Val Acc: 55.53%
Epoch 20/100, Train Loss: 1.324282, Train Acc: 52.21%, Val Loss: 1.226737, Val Acc: 56.08%
Epoch 21/100, Train Loss: 1.309528, Train Acc: 52.88%, Val Loss: 1.216532, Val Acc: 56.64%
Epoch 22/100, Train Loss: 1.297897, Train Acc: 53.29%, Val Loss: 1.208040, Val Acc: 56.47%
Epoch 23/100, Train Loss: 1.285042, Train Acc: 53.71%, Val Loss: 1.201134, Val Acc: 57.01%
Epoch 24/100, Train Loss: 1.278702, Train Acc: 54.14%, Val Loss: 1.182319, Val Acc: 57.56%
Epoch 25/100, Train Loss: 1.264277, Train Acc: 54.61%, Val Loss: 1.181047, Val Acc: 58.10%
Epoch 26/100, Train Loss: 1.257583, Train Acc: 54.76%, Val Loss: 1.188159, Val Acc: 57.96%
Epoch 27/100, Train Loss: 1.237244, Train Acc: 55.63%, Val Loss: 1.155535, Val Acc: 59.12%
Epoch 28/100, Train Loss: 1.230237, Train Acc: 55.90%, Val Loss: 1.158880, Val Acc: 58.95%
Epoch 29/100, Train Loss: 1.226774, Train Acc: 56.20%, Val Loss: 1.131821, Val Acc: 59.77%
Epoch 30/100, Train Loss: 1.212215, Train Acc: 56.48%, Val Loss: 1.126861, Val Acc: 60.58%
Epoch 31/100, Train Loss: 1.201195, Train Acc: 57.39%, Val Loss: 1.120068, Val Acc: 60.52%
Epoch 32/100, Train Loss: 1.199721, Train Acc: 57.38%, Val Loss: 1.115598, Val Acc: 60.54%
Epoch 33/100, Train Loss: 1.184343, Train Acc: 57.65%, Val Loss: 1.103833, Val Acc: 60.98%
Epoch 34/100, Train Loss: 1.179958, Train Acc: 57.98%, Val Loss: 1.103708, Val Acc: 60.99%
Epoch 35/100, Train Loss: 1.168959, Train Acc: 58.20%, Val Loss: 1.097046, Val Acc: 61.32%
Epoch 36/100, Train Loss: 1.158038, Train Acc: 58.77%, Val Loss: 1.078035, Val Acc: 62.44%
Epoch 37/100, Train Loss: 1.148423, Train Acc: 59.29%, Val Loss: 1.079923, Val Acc: 62.06%
Epoch 38/100, Train Loss: 1.150474, Train Acc: 58.97%, Val Loss: 1.071340, Val Acc: 61.96%
Epoch 39/100, Train Loss: 1.135065, Train Acc: 59.46%, Val Loss: 1.070113, Val Acc: 62.50%
Epoch 40/100, Train Loss: 1.129771, Train Acc: 59.67%, Val Loss: 1.054431, Val Acc: 62.74%
Epoch 41/100, Train Loss: 1.123352, Train Acc: 59.69%, Val Loss: 1.051993, Val Acc: 62.89%
Epoch 42/100, Train Loss: 1.108012, Train Acc: 60.28%, Val Loss: 1.041396, Val Acc: 63.24%
Epoch 43/100, Train Loss: 1.106920, Train Acc: 60.66%, Val Loss: 1.034098, Val Acc: 63.30%
Epoch 44/100, Train Loss: 1.099196, Train Acc: 61.04%, Val Loss: 1.024705, Val Acc: 63.56%
Epoch 45/100, Train Loss: 1.092994, Train Acc: 61.18%, Val Loss: 1.021190, Val Acc: 64.14%
Epoch 46/100, Train Loss: 1.090183, Train Acc: 60.94%, Val Loss: 1.023621, Val Acc: 63.65%
Epoch 47/100, Train Loss: 1.076863, Train Acc: 61.71%, Val Loss: 1.021540, Val Acc: 63.80%
Epoch 48/100, Train Loss: 1.079055, Train Acc: 61.60%, Val Loss: 1.011823, Val Acc: 64.23%
Epoch 49/100, Train Loss: 1.068860, Train Acc: 62.00%, Val Loss: 0.998602, Val Acc: 64.83%
Epoch 50/100, Train Loss: 1.064854, Train Acc: 62.24%, Val Loss: 1.006638, Val Acc: 64.54%
Epoch 51/100, Train Loss: 1.059021, Train Acc: 62.54%, Val Loss: 0.987766, Val Acc: 64.93%
Epoch 52/100, Train Loss: 1.052620, Train Acc: 62.68%, Val Loss: 0.983041, Val Acc: 65.03%
Epoch 53/100, Train Loss: 1.046011, Train Acc: 62.95%, Val Loss: 0.984535, Val Acc: 65.16%
Epoch 54/100, Train Loss: 1.042926, Train Acc: 63.10%, Val Loss: 0.972683, Val Acc: 65.42%
Epoch 55/100, Train Loss: 1.034747, Train Acc: 63.01%, Val Loss: 0.970133, Val Acc: 65.79%
Epoch 56/100, Train Loss: 1.028408, Train Acc: 63.60%, Val Loss: 0.969305, Val Acc: 65.76%
Epoch 57/100, Train Loss: 1.025411, Train Acc: 63.68%, Val Loss: 0.968392, Val Acc: 65.86%
Epoch 58/100, Train Loss: 1.019328, Train Acc: 63.78%, Val Loss: 0.956810, Val Acc: 66.19%
Epoch 59/100, Train Loss: 1.014318, Train Acc: 63.78%, Val Loss: 0.956037, Val Acc: 66.35%
Epoch 60/100, Train Loss: 1.008711, Train Acc: 64.25%, Val Loss: 0.945588, Val Acc: 66.67%
Epoch 61/100, Train Loss: 1.004189, Train Acc: 64.49%, Val Loss: 0.954243, Val Acc: 66.22%
Epoch 62/100, Train Loss: 1.002552, Train Acc: 64.48%, Val Loss: 0.942669, Val Acc: 66.66%
Epoch 63/100, Train Loss: 0.994117, Train Acc: 64.52%, Val Loss: 0.941744, Val Acc: 66.74%
Epoch 64/100, Train Loss: 0.992890, Train Acc: 64.79%, Val Loss: 0.933030, Val Acc: 67.25%
Epoch 65/100, Train Loss: 0.986723, Train Acc: 65.06%, Val Loss: 0.925407, Val Acc: 67.39%
Epoch 66/100, Train Loss: 0.982655, Train Acc: 65.26%, Val Loss: 0.932949, Val Acc: 67.25%
Epoch 67/100, Train Loss: 0.977752, Train Acc: 65.32%, Val Loss: 0.925964, Val Acc: 67.63%
Epoch 68/100, Train Loss: 0.972055, Train Acc: 65.80%, Val Loss: 0.917181, Val Acc: 67.83%
Epoch 69/100, Train Loss: 0.973330, Train Acc: 65.33%, Val Loss: 0.908600, Val Acc: 67.86%
Epoch 70/100, Train Loss: 0.966338, Train Acc: 65.66%, Val Loss: 0.919852, Val Acc: 68.00%
Epoch 71/100, Train Loss: 0.962447, Train Acc: 65.67%, Val Loss: 0.905291, Val Acc: 68.36%
Epoch 72/100, Train Loss: 0.963009, Train Acc: 65.87%, Val Loss: 0.900921, Val Acc: 68.22%
Epoch 73/100, Train Loss: 0.953286, Train Acc: 66.23%, Val Loss: 0.917136, Val Acc: 67.95%
Epoch 74/100, Train Loss: 0.951783, Train Acc: 66.37%, Val Loss: 0.908822, Val Acc: 68.41%
Epoch 75/100, Train Loss: 0.949806, Train Acc: 66.35%, Val Loss: 0.909933, Val Acc: 68.37%
Epoch 76/100, Train Loss: 0.940236, Train Acc: 66.79%, Val Loss: 0.895957, Val Acc: 68.79%
Epoch 77/100, Train Loss: 0.943775, Train Acc: 66.91%, Val Loss: 0.890616, Val Acc: 68.90%
Epoch 78/100, Train Loss: 0.937695, Train Acc: 66.77%, Val Loss: 0.897789, Val Acc: 68.03%
Epoch 79/100, Train Loss: 0.932074, Train Acc: 67.07%, Val Loss: 0.888945, Val Acc: 68.85%
Epoch 80/100, Train Loss: 0.929406, Train Acc: 67.16%, Val Loss: 0.888802, Val Acc: 69.28%
Epoch 81/100, Train Loss: 0.929041, Train Acc: 67.14%, Val Loss: 0.868985, Val Acc: 69.43%
Epoch 82/100, Train Loss: 0.923876, Train Acc: 67.11%, Val Loss: 0.881698, Val Acc: 69.02%
Epoch 83/100, Train Loss: 0.921042, Train Acc: 67.57%, Val Loss: 0.876042, Val Acc: 69.12%
Epoch 84/100, Train Loss: 0.916601, Train Acc: 67.55%, Val Loss: 0.883341, Val Acc: 69.18%
Epoch 85/100, Train Loss: 0.915147, Train Acc: 67.70%, Val Loss: 0.872056, Val Acc: 69.66%
Epoch 86/100, Train Loss: 0.911073, Train Acc: 67.91%, Val Loss: 0.866186, Val Acc: 69.61%
Epoch 87/100, Train Loss: 0.912952, Train Acc: 67.59%, Val Loss: 0.868503, Val Acc: 69.58%
Epoch 88/100, Train Loss: 0.904798, Train Acc: 67.99%, Val Loss: 0.865853, Val Acc: 69.99%
Epoch 89/100, Train Loss: 0.901628, Train Acc: 68.25%, Val Loss: 0.862373, Val Acc: 69.81%
Epoch 90/100, Train Loss: 0.904655, Train Acc: 68.17%, Val Loss: 0.853675, Val Acc: 70.01%
Epoch 91/100, Train Loss: 0.897543, Train Acc: 68.08%, Val Loss: 0.880614, Val Acc: 68.80%
Epoch 92/100, Train Loss: 0.893505, Train Acc: 68.44%, Val Loss: 0.865417, Val Acc: 69.59%
Epoch 93/100, Train Loss: 0.893803, Train Acc: 68.57%, Val Loss: 0.852116, Val Acc: 70.06%
Epoch 94/100, Train Loss: 0.890756, Train Acc: 68.55%, Val Loss: 0.862541, Val Acc: 69.83%
Epoch 95/100, Train Loss: 0.887013, Train Acc: 68.52%, Val Loss: 0.856951, Val Acc: 69.94%
Epoch 96/100, Train Loss: 0.881805, Train Acc: 68.86%, Val Loss: 0.850754, Val Acc: 69.90%
Epoch 97/100, Train Loss: 0.876792, Train Acc: 69.08%, Val Loss: 0.839528, Val Acc: 70.53%
Epoch 98/100, Train Loss: 0.876208, Train Acc: 69.09%, Val Loss: 0.843047, Val Acc: 70.43%
Epoch 99/100, Train Loss: 0.874257, Train Acc: 69.08%, Val Loss: 0.849459, Val Acc: 69.74%
Epoch 100/100, Train Loss: 0.871223, Train Acc: 69.20%, Val Loss: 0.839569, Val Acc: 70.93%
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7093}]
Valore m[value]:  0.7093
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7093
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.870173, Train Acc: 69.22%, Val Loss: 0.843417, Val Acc: 70.13%
Epoch 2/100, Train Loss: 0.865029, Train Acc: 69.69%, Val Loss: 0.836664, Val Acc: 70.38%
Epoch 3/100, Train Loss: 0.865679, Train Acc: 69.62%, Val Loss: 0.839691, Val Acc: 70.90%
Epoch 4/100, Train Loss: 0.864351, Train Acc: 69.51%, Val Loss: 0.844929, Val Acc: 70.43%
Epoch 5/100, Train Loss: 0.856718, Train Acc: 69.55%, Val Loss: 0.820513, Val Acc: 71.29%
Epoch 6/100, Train Loss: 0.857505, Train Acc: 69.73%, Val Loss: 0.821559, Val Acc: 71.46%
Epoch 7/100, Train Loss: 0.854380, Train Acc: 70.10%, Val Loss: 0.824504, Val Acc: 71.33%
Epoch 8/100, Train Loss: 0.849528, Train Acc: 69.99%, Val Loss: 0.829901, Val Acc: 70.95%
Epoch 9/100, Train Loss: 0.847246, Train Acc: 69.94%, Val Loss: 0.820495, Val Acc: 71.00%
Epoch 10/100, Train Loss: 0.847950, Train Acc: 70.05%, Val Loss: 0.813169, Val Acc: 71.29%
Epoch 11/100, Train Loss: 0.839393, Train Acc: 70.34%, Val Loss: 0.812224, Val Acc: 71.45%
Epoch 12/100, Train Loss: 0.842717, Train Acc: 70.30%, Val Loss: 0.822395, Val Acc: 71.15%
Epoch 13/100, Train Loss: 0.845932, Train Acc: 70.37%, Val Loss: 0.821613, Val Acc: 71.26%
Epoch 14/100, Train Loss: 0.835917, Train Acc: 70.49%, Val Loss: 0.811632, Val Acc: 71.62%
Epoch 15/100, Train Loss: 0.842479, Train Acc: 70.36%, Val Loss: 0.814269, Val Acc: 71.52%
Epoch 16/100, Train Loss: 0.831972, Train Acc: 70.54%, Val Loss: 0.799227, Val Acc: 71.71%
Epoch 17/100, Train Loss: 0.831985, Train Acc: 70.65%, Val Loss: 0.799208, Val Acc: 71.93%
Epoch 18/100, Train Loss: 0.828015, Train Acc: 71.01%, Val Loss: 0.815696, Val Acc: 71.67%
Epoch 19/100, Train Loss: 0.830276, Train Acc: 70.78%, Val Loss: 0.800588, Val Acc: 71.98%
Epoch 20/100, Train Loss: 0.826108, Train Acc: 70.79%, Val Loss: 0.797073, Val Acc: 71.82%
Epoch 21/100, Train Loss: 0.822744, Train Acc: 71.06%, Val Loss: 0.808988, Val Acc: 71.59%
Epoch 22/100, Train Loss: 0.823329, Train Acc: 71.19%, Val Loss: 0.800702, Val Acc: 71.82%
Epoch 23/100, Train Loss: 0.819112, Train Acc: 71.14%, Val Loss: 0.788953, Val Acc: 72.07%
Epoch 24/100, Train Loss: 0.815541, Train Acc: 71.33%, Val Loss: 0.786382, Val Acc: 72.33%
Epoch 25/100, Train Loss: 0.815652, Train Acc: 71.45%, Val Loss: 0.794531, Val Acc: 72.11%
Epoch 26/100, Train Loss: 0.814499, Train Acc: 71.63%, Val Loss: 0.787365, Val Acc: 72.08%
Epoch 27/100, Train Loss: 0.811145, Train Acc: 71.56%, Val Loss: 0.796440, Val Acc: 71.92%
Epoch 28/100, Train Loss: 0.809823, Train Acc: 71.59%, Val Loss: 0.797581, Val Acc: 72.08%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7211}]
Valore m[value]:  0.7211
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7211
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.808047, Train Acc: 71.72%, Val Loss: 0.794532, Val Acc: 72.37%
Epoch 2/100, Train Loss: 0.803887, Train Acc: 71.86%, Val Loss: 0.776101, Val Acc: 72.61%
Epoch 3/100, Train Loss: 0.801930, Train Acc: 71.96%, Val Loss: 0.777744, Val Acc: 72.75%
Epoch 4/100, Train Loss: 0.803089, Train Acc: 71.66%, Val Loss: 0.769620, Val Acc: 72.79%
Epoch 5/100, Train Loss: 0.800603, Train Acc: 71.89%, Val Loss: 0.775120, Val Acc: 72.86%
Epoch 6/100, Train Loss: 0.800923, Train Acc: 71.72%, Val Loss: 0.780758, Val Acc: 72.56%
Epoch 7/100, Train Loss: 0.797507, Train Acc: 71.92%, Val Loss: 0.774401, Val Acc: 72.75%
Epoch 8/100, Train Loss: 0.793615, Train Acc: 72.16%, Val Loss: 0.773493, Val Acc: 73.25%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7303}]
Valore m[value]:  0.7303
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7303
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.791297, Train Acc: 71.92%, Val Loss: 0.769122, Val Acc: 72.88%
Epoch 2/100, Train Loss: 0.789303, Train Acc: 72.20%, Val Loss: 0.778444, Val Acc: 72.93%
Epoch 3/100, Train Loss: 0.786034, Train Acc: 72.33%, Val Loss: 0.774180, Val Acc: 73.04%
Epoch 4/100, Train Loss: 0.783045, Train Acc: 72.66%, Val Loss: 0.769388, Val Acc: 73.04%
Epoch 5/100, Train Loss: 0.788707, Train Acc: 72.36%, Val Loss: 0.760362, Val Acc: 72.71%
Epoch 6/100, Train Loss: 0.783711, Train Acc: 72.45%, Val Loss: 0.761602, Val Acc: 73.15%
Epoch 7/100, Train Loss: 0.780422, Train Acc: 72.57%, Val Loss: 0.760845, Val Acc: 73.29%
Epoch 8/100, Train Loss: 0.784805, Train Acc: 72.58%, Val Loss: 0.761175, Val Acc: 72.94%
Epoch 9/100, Train Loss: 0.781055, Train Acc: 72.80%, Val Loss: 0.768476, Val Acc: 73.25%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7308}]
Valore m[value]:  0.7308
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7308
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.777843, Train Acc: 72.62%, Val Loss: 0.761230, Val Acc: 73.38%
Epoch 2/100, Train Loss: 0.776251, Train Acc: 72.76%, Val Loss: 0.765750, Val Acc: 73.27%
Epoch 3/100, Train Loss: 0.776004, Train Acc: 73.07%, Val Loss: 0.759104, Val Acc: 73.32%
Epoch 4/100, Train Loss: 0.771148, Train Acc: 73.15%, Val Loss: 0.751726, Val Acc: 73.43%
Epoch 5/100, Train Loss: 0.770704, Train Acc: 73.06%, Val Loss: 0.753944, Val Acc: 73.50%
Epoch 6/100, Train Loss: 0.769704, Train Acc: 73.07%, Val Loss: 0.759680, Val Acc: 73.16%
Epoch 7/100, Train Loss: 0.764022, Train Acc: 73.32%, Val Loss: 0.749462, Val Acc: 73.35%
Epoch 8/100, Train Loss: 0.763075, Train Acc: 73.35%, Val Loss: 0.748099, Val Acc: 73.85%
Epoch 9/100, Train Loss: 0.767158, Train Acc: 73.08%, Val Loss: 0.746933, Val Acc: 73.95%
Epoch 10/100, Train Loss: 0.766866, Train Acc: 73.05%, Val Loss: 0.745093, Val Acc: 73.81%
Epoch 11/100, Train Loss: 0.758730, Train Acc: 73.50%, Val Loss: 0.754042, Val Acc: 73.79%
Epoch 12/100, Train Loss: 0.762299, Train Acc: 73.25%, Val Loss: 0.756389, Val Acc: 73.36%
Epoch 13/100, Train Loss: 0.755818, Train Acc: 73.58%, Val Loss: 0.774432, Val Acc: 72.86%
Epoch 14/100, Train Loss: 0.757066, Train Acc: 73.50%, Val Loss: 0.757449, Val Acc: 73.54%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7392}]
Valore m[value]:  0.7392
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7392
	Requirements not satisfied! Continue training ... 
Reached half of the maximum attempts, reallocating model...
Epoch 1/100, Train Loss: 0.761001, Train Acc: 73.26%, Val Loss: 0.744415, Val Acc: 73.91%
Epoch 2/100, Train Loss: 0.757079, Train Acc: 73.48%, Val Loss: 0.735376, Val Acc: 74.33%
Epoch 3/100, Train Loss: 0.754771, Train Acc: 73.49%, Val Loss: 0.741346, Val Acc: 74.11%
Epoch 4/100, Train Loss: 0.751129, Train Acc: 73.58%, Val Loss: 0.738385, Val Acc: 74.06%
Epoch 5/100, Train Loss: 0.751159, Train Acc: 73.80%, Val Loss: 0.748170, Val Acc: 73.53%
Epoch 6/100, Train Loss: 0.750892, Train Acc: 73.65%, Val Loss: 0.737539, Val Acc: 74.15%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.74}]
Valore m[value]:  0.74
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.74
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.748072, Train Acc: 73.88%, Val Loss: 0.724883, Val Acc: 74.49%
Epoch 2/100, Train Loss: 0.745962, Train Acc: 73.83%, Val Loss: 0.743422, Val Acc: 74.16%
Epoch 3/100, Train Loss: 0.748002, Train Acc: 73.93%, Val Loss: 0.732181, Val Acc: 74.30%
Epoch 4/100, Train Loss: 0.740816, Train Acc: 74.33%, Val Loss: 0.740993, Val Acc: 74.25%
Epoch 5/100, Train Loss: 0.745228, Train Acc: 73.80%, Val Loss: 0.726074, Val Acc: 74.67%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7448}]
Valore m[value]:  0.7448
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7448
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.743663, Train Acc: 74.06%, Val Loss: 0.725599, Val Acc: 74.92%
Epoch 2/100, Train Loss: 0.739372, Train Acc: 74.24%, Val Loss: 0.721058, Val Acc: 75.00%
Epoch 3/100, Train Loss: 0.741830, Train Acc: 74.08%, Val Loss: 0.731747, Val Acc: 74.44%
Epoch 4/100, Train Loss: 0.735841, Train Acc: 74.36%, Val Loss: 0.744011, Val Acc: 74.21%
Epoch 5/100, Train Loss: 0.736291, Train Acc: 74.20%, Val Loss: 0.744075, Val Acc: 74.40%
Epoch 6/100, Train Loss: 0.737635, Train Acc: 74.03%, Val Loss: 0.745839, Val Acc: 74.41%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7466}]
Valore m[value]:  0.7466
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7466
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.733449, Train Acc: 74.35%, Val Loss: 0.720236, Val Acc: 74.97%
Epoch 2/100, Train Loss: 0.730150, Train Acc: 74.49%, Val Loss: 0.723323, Val Acc: 74.94%
Epoch 3/100, Train Loss: 0.730637, Train Acc: 74.60%, Val Loss: 0.716473, Val Acc: 74.99%
Epoch 4/100, Train Loss: 0.733343, Train Acc: 74.57%, Val Loss: 0.729269, Val Acc: 74.81%
Epoch 5/100, Train Loss: 0.727619, Train Acc: 74.50%, Val Loss: 0.720044, Val Acc: 74.81%
Epoch 6/100, Train Loss: 0.725504, Train Acc: 74.57%, Val Loss: 0.723535, Val Acc: 75.21%
Epoch 7/100, Train Loss: 0.730106, Train Acc: 74.52%, Val Loss: 0.726576, Val Acc: 74.99%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7395}]
Valore m[value]:  0.7395
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7395
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.723534, Train Acc: 75.05%, Val Loss: 0.729554, Val Acc: 74.85%
Epoch 2/100, Train Loss: 0.727040, Train Acc: 74.64%, Val Loss: 0.713463, Val Acc: 75.44%
Epoch 3/100, Train Loss: 0.720956, Train Acc: 74.91%, Val Loss: 0.713926, Val Acc: 75.33%
Epoch 4/100, Train Loss: 0.725005, Train Acc: 74.74%, Val Loss: 0.710915, Val Acc: 75.39%
Epoch 5/100, Train Loss: 0.719730, Train Acc: 74.91%, Val Loss: 0.706557, Val Acc: 75.36%
Epoch 6/100, Train Loss: 0.715340, Train Acc: 74.95%, Val Loss: 0.715419, Val Acc: 75.16%
Epoch 7/100, Train Loss: 0.718184, Train Acc: 74.68%, Val Loss: 0.719344, Val Acc: 75.12%
Epoch 8/100, Train Loss: 0.720257, Train Acc: 74.93%, Val Loss: 0.710177, Val Acc: 75.39%
Epoch 9/100, Train Loss: 0.716835, Train Acc: 74.93%, Val Loss: 0.712549, Val Acc: 75.47%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7511}]
Valore m[value]:  0.7511
	Requirements satisfied! Reducing model ... 
Saving mid model... 
String Index to remove:  1
DEVO RIMUOVERE:  {'index': '1', 'type': 'Sequential', 'layers': [{'index': '1.0', 'type': 'Conv2d', 'args': {'in_channels': 2, 'out_channels': 8, 'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': 1, 'padding_mode': 'zeros'}}, {'index': '1.1', 'type': 'BatchNorm2d', 'args': {'num_features': 8, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}}, {'index': '1.2', 'type': 'ReLU', 'args': {'inplace': False}}]}
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 12},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1}]
Reduction ratio: 0.7
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (12): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (13): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (12): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.194636, Train Acc: 17.30%, Val Loss: 1.910604, Val Acc: 27.99%
Epoch 2/100, Train Loss: 1.865015, Train Acc: 29.83%, Val Loss: 1.704471, Val Acc: 37.88%
Epoch 3/100, Train Loss: 1.760895, Train Acc: 34.19%, Val Loss: 1.639645, Val Acc: 40.20%
Epoch 4/100, Train Loss: 1.695690, Train Acc: 36.88%, Val Loss: 1.573049, Val Acc: 42.48%
Epoch 5/100, Train Loss: 1.648578, Train Acc: 39.19%, Val Loss: 1.522036, Val Acc: 44.49%
Epoch 6/100, Train Loss: 1.602277, Train Acc: 40.86%, Val Loss: 1.488572, Val Acc: 45.27%
Epoch 7/100, Train Loss: 1.560981, Train Acc: 42.58%, Val Loss: 1.470950, Val Acc: 45.70%
Epoch 8/100, Train Loss: 1.529704, Train Acc: 43.74%, Val Loss: 1.441502, Val Acc: 47.05%
Epoch 9/100, Train Loss: 1.500980, Train Acc: 44.98%, Val Loss: 1.392968, Val Acc: 48.89%
Epoch 10/100, Train Loss: 1.474461, Train Acc: 45.87%, Val Loss: 1.374866, Val Acc: 49.78%
Epoch 11/100, Train Loss: 1.451670, Train Acc: 47.21%, Val Loss: 1.358197, Val Acc: 50.31%
Epoch 12/100, Train Loss: 1.432546, Train Acc: 47.74%, Val Loss: 1.356605, Val Acc: 50.49%
Epoch 13/100, Train Loss: 1.407562, Train Acc: 48.48%, Val Loss: 1.306854, Val Acc: 52.44%
Epoch 14/100, Train Loss: 1.391713, Train Acc: 49.27%, Val Loss: 1.320419, Val Acc: 51.88%
Epoch 15/100, Train Loss: 1.378132, Train Acc: 49.76%, Val Loss: 1.278030, Val Acc: 53.58%
Epoch 16/100, Train Loss: 1.358406, Train Acc: 50.51%, Val Loss: 1.264851, Val Acc: 54.67%
Epoch 17/100, Train Loss: 1.338449, Train Acc: 51.54%, Val Loss: 1.245040, Val Acc: 55.07%
Epoch 18/100, Train Loss: 1.327151, Train Acc: 51.93%, Val Loss: 1.246169, Val Acc: 55.00%
Epoch 19/100, Train Loss: 1.313969, Train Acc: 52.40%, Val Loss: 1.215319, Val Acc: 55.94%
Epoch 20/100, Train Loss: 1.298831, Train Acc: 52.91%, Val Loss: 1.206806, Val Acc: 56.22%
Epoch 21/100, Train Loss: 1.285371, Train Acc: 53.43%, Val Loss: 1.192121, Val Acc: 57.13%
Epoch 22/100, Train Loss: 1.275464, Train Acc: 53.88%, Val Loss: 1.181582, Val Acc: 57.32%
Epoch 23/100, Train Loss: 1.260395, Train Acc: 54.66%, Val Loss: 1.179336, Val Acc: 57.33%
Epoch 24/100, Train Loss: 1.251217, Train Acc: 54.94%, Val Loss: 1.151837, Val Acc: 58.69%
Epoch 25/100, Train Loss: 1.241272, Train Acc: 55.08%, Val Loss: 1.147752, Val Acc: 58.79%
Epoch 26/100, Train Loss: 1.227067, Train Acc: 55.82%, Val Loss: 1.151442, Val Acc: 58.72%
Epoch 27/100, Train Loss: 1.213291, Train Acc: 56.34%, Val Loss: 1.124380, Val Acc: 59.51%
Epoch 28/100, Train Loss: 1.203523, Train Acc: 56.79%, Val Loss: 1.114736, Val Acc: 60.01%
Epoch 29/100, Train Loss: 1.197898, Train Acc: 56.96%, Val Loss: 1.113603, Val Acc: 59.73%
Epoch 30/100, Train Loss: 1.185986, Train Acc: 57.56%, Val Loss: 1.100772, Val Acc: 60.70%
Epoch 31/100, Train Loss: 1.173069, Train Acc: 57.90%, Val Loss: 1.079941, Val Acc: 61.21%
Epoch 32/100, Train Loss: 1.169917, Train Acc: 58.01%, Val Loss: 1.077266, Val Acc: 61.84%
Epoch 33/100, Train Loss: 1.165388, Train Acc: 58.33%, Val Loss: 1.069438, Val Acc: 61.61%
Epoch 34/100, Train Loss: 1.151480, Train Acc: 58.78%, Val Loss: 1.068347, Val Acc: 61.53%
Epoch 35/100, Train Loss: 1.147241, Train Acc: 58.93%, Val Loss: 1.052693, Val Acc: 62.52%
Epoch 36/100, Train Loss: 1.137652, Train Acc: 59.45%, Val Loss: 1.045061, Val Acc: 62.54%
Epoch 37/100, Train Loss: 1.133947, Train Acc: 59.33%, Val Loss: 1.035538, Val Acc: 63.08%
Epoch 38/100, Train Loss: 1.120693, Train Acc: 59.87%, Val Loss: 1.029938, Val Acc: 63.23%
Epoch 39/100, Train Loss: 1.110725, Train Acc: 60.27%, Val Loss: 1.019921, Val Acc: 63.50%
Epoch 40/100, Train Loss: 1.105579, Train Acc: 60.43%, Val Loss: 1.009908, Val Acc: 64.08%
Epoch 41/100, Train Loss: 1.099454, Train Acc: 60.66%, Val Loss: 1.002527, Val Acc: 64.11%
Epoch 42/100, Train Loss: 1.095048, Train Acc: 60.91%, Val Loss: 1.014515, Val Acc: 63.99%
Epoch 43/100, Train Loss: 1.085145, Train Acc: 61.15%, Val Loss: 1.006129, Val Acc: 64.23%
Epoch 44/100, Train Loss: 1.075294, Train Acc: 61.81%, Val Loss: 0.989129, Val Acc: 64.71%
Epoch 45/100, Train Loss: 1.070922, Train Acc: 61.74%, Val Loss: 0.982911, Val Acc: 64.69%
Epoch 46/100, Train Loss: 1.068834, Train Acc: 61.92%, Val Loss: 0.983404, Val Acc: 64.72%
Epoch 47/100, Train Loss: 1.061775, Train Acc: 62.12%, Val Loss: 0.972712, Val Acc: 65.06%
Epoch 48/100, Train Loss: 1.052952, Train Acc: 62.50%, Val Loss: 0.963157, Val Acc: 65.72%
Epoch 49/100, Train Loss: 1.054722, Train Acc: 62.33%, Val Loss: 0.974821, Val Acc: 65.02%
Epoch 50/100, Train Loss: 1.041920, Train Acc: 62.97%, Val Loss: 0.965758, Val Acc: 65.74%
Epoch 51/100, Train Loss: 1.040929, Train Acc: 62.82%, Val Loss: 0.951671, Val Acc: 66.06%
Epoch 52/100, Train Loss: 1.034094, Train Acc: 63.36%, Val Loss: 0.944324, Val Acc: 66.19%
Epoch 53/100, Train Loss: 1.025281, Train Acc: 63.60%, Val Loss: 0.951622, Val Acc: 65.90%
Epoch 54/100, Train Loss: 1.019022, Train Acc: 63.52%, Val Loss: 0.936840, Val Acc: 66.54%
Epoch 55/100, Train Loss: 1.016896, Train Acc: 63.75%, Val Loss: 0.931200, Val Acc: 66.73%
Epoch 56/100, Train Loss: 1.019120, Train Acc: 63.57%, Val Loss: 0.938138, Val Acc: 66.60%
Epoch 57/100, Train Loss: 1.011309, Train Acc: 63.84%, Val Loss: 0.933900, Val Acc: 66.47%
Epoch 58/100, Train Loss: 1.005717, Train Acc: 64.14%, Val Loss: 0.928353, Val Acc: 66.92%
Epoch 59/100, Train Loss: 1.000338, Train Acc: 64.48%, Val Loss: 0.918083, Val Acc: 67.21%
Epoch 60/100, Train Loss: 0.996709, Train Acc: 64.45%, Val Loss: 0.930819, Val Acc: 66.84%
Epoch 61/100, Train Loss: 0.991983, Train Acc: 64.86%, Val Loss: 0.907776, Val Acc: 67.52%
Epoch 62/100, Train Loss: 0.985679, Train Acc: 64.92%, Val Loss: 0.921511, Val Acc: 66.84%
Epoch 63/100, Train Loss: 0.989020, Train Acc: 65.12%, Val Loss: 0.924682, Val Acc: 67.05%
Epoch 64/100, Train Loss: 0.987051, Train Acc: 65.01%, Val Loss: 0.904464, Val Acc: 67.97%
Epoch 65/100, Train Loss: 0.979120, Train Acc: 65.20%, Val Loss: 0.901585, Val Acc: 67.76%
Epoch 66/100, Train Loss: 0.974932, Train Acc: 65.13%, Val Loss: 0.891153, Val Acc: 67.83%
Epoch 67/100, Train Loss: 0.973859, Train Acc: 65.46%, Val Loss: 0.890877, Val Acc: 68.14%
Epoch 68/100, Train Loss: 0.959029, Train Acc: 65.89%, Val Loss: 0.901821, Val Acc: 67.74%
Epoch 69/100, Train Loss: 0.963874, Train Acc: 65.63%, Val Loss: 0.898055, Val Acc: 68.00%
Epoch 70/100, Train Loss: 0.956266, Train Acc: 66.04%, Val Loss: 0.877508, Val Acc: 68.41%
Epoch 71/100, Train Loss: 0.953760, Train Acc: 65.97%, Val Loss: 0.892267, Val Acc: 68.20%
Epoch 72/100, Train Loss: 0.952364, Train Acc: 66.03%, Val Loss: 0.883424, Val Acc: 68.13%
Epoch 73/100, Train Loss: 0.944726, Train Acc: 66.30%, Val Loss: 0.876359, Val Acc: 68.56%
Epoch 74/100, Train Loss: 0.942625, Train Acc: 66.42%, Val Loss: 0.876762, Val Acc: 68.48%
Epoch 75/100, Train Loss: 0.943554, Train Acc: 66.42%, Val Loss: 0.875597, Val Acc: 68.89%
Epoch 76/100, Train Loss: 0.933798, Train Acc: 66.63%, Val Loss: 0.870703, Val Acc: 68.70%
Epoch 77/100, Train Loss: 0.930855, Train Acc: 66.92%, Val Loss: 0.864072, Val Acc: 69.36%
Epoch 78/100, Train Loss: 0.930552, Train Acc: 66.88%, Val Loss: 0.854260, Val Acc: 69.54%
Epoch 79/100, Train Loss: 0.928977, Train Acc: 67.06%, Val Loss: 0.859819, Val Acc: 69.49%
Epoch 80/100, Train Loss: 0.921744, Train Acc: 67.11%, Val Loss: 0.858955, Val Acc: 69.20%
Epoch 81/100, Train Loss: 0.921481, Train Acc: 67.32%, Val Loss: 0.860083, Val Acc: 69.39%
Epoch 82/100, Train Loss: 0.920487, Train Acc: 67.48%, Val Loss: 0.856765, Val Acc: 69.86%
Epoch 83/100, Train Loss: 0.914136, Train Acc: 67.51%, Val Loss: 0.847796, Val Acc: 69.75%
Epoch 84/100, Train Loss: 0.912312, Train Acc: 67.55%, Val Loss: 0.848367, Val Acc: 70.11%
Epoch 85/100, Train Loss: 0.909448, Train Acc: 67.56%, Val Loss: 0.854847, Val Acc: 69.47%
Epoch 86/100, Train Loss: 0.905845, Train Acc: 67.88%, Val Loss: 0.842833, Val Acc: 69.95%
Epoch 87/100, Train Loss: 0.907106, Train Acc: 67.65%, Val Loss: 0.838289, Val Acc: 70.22%
Epoch 88/100, Train Loss: 0.903706, Train Acc: 67.86%, Val Loss: 0.838668, Val Acc: 70.28%
Epoch 89/100, Train Loss: 0.897981, Train Acc: 68.31%, Val Loss: 0.834539, Val Acc: 70.33%
Epoch 90/100, Train Loss: 0.900185, Train Acc: 68.10%, Val Loss: 0.842909, Val Acc: 70.25%
Epoch 91/100, Train Loss: 0.891637, Train Acc: 68.46%, Val Loss: 0.838057, Val Acc: 70.68%
Epoch 92/100, Train Loss: 0.887006, Train Acc: 68.62%, Val Loss: 0.835542, Val Acc: 70.51%
Epoch 93/100, Train Loss: 0.892069, Train Acc: 68.41%, Val Loss: 0.822943, Val Acc: 70.74%
Epoch 94/100, Train Loss: 0.885211, Train Acc: 68.85%, Val Loss: 0.831850, Val Acc: 70.39%
Epoch 95/100, Train Loss: 0.880334, Train Acc: 68.85%, Val Loss: 0.824223, Val Acc: 71.00%
Epoch 96/100, Train Loss: 0.880990, Train Acc: 69.07%, Val Loss: 0.825978, Val Acc: 70.61%
Epoch 97/100, Train Loss: 0.875471, Train Acc: 69.23%, Val Loss: 0.826949, Val Acc: 70.56%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7123}]
Valore m[value]:  0.7123
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7123
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.868846, Train Acc: 69.36%, Val Loss: 0.815417, Val Acc: 71.66%
Epoch 2/100, Train Loss: 0.874672, Train Acc: 68.99%, Val Loss: 0.820934, Val Acc: 71.44%
Epoch 3/100, Train Loss: 0.869783, Train Acc: 69.21%, Val Loss: 0.806989, Val Acc: 71.63%
Epoch 4/100, Train Loss: 0.866971, Train Acc: 69.16%, Val Loss: 0.809956, Val Acc: 71.59%
Epoch 5/100, Train Loss: 0.860844, Train Acc: 69.59%, Val Loss: 0.816665, Val Acc: 71.12%
Epoch 6/100, Train Loss: 0.859624, Train Acc: 69.75%, Val Loss: 0.804299, Val Acc: 71.71%
Epoch 7/100, Train Loss: 0.860120, Train Acc: 69.57%, Val Loss: 0.807509, Val Acc: 71.52%
Epoch 8/100, Train Loss: 0.857708, Train Acc: 69.94%, Val Loss: 0.808771, Val Acc: 71.63%
Epoch 9/100, Train Loss: 0.854409, Train Acc: 69.84%, Val Loss: 0.808694, Val Acc: 71.63%
Epoch 10/100, Train Loss: 0.853957, Train Acc: 69.79%, Val Loss: 0.804464, Val Acc: 71.95%
Epoch 11/100, Train Loss: 0.853138, Train Acc: 69.98%, Val Loss: 0.795820, Val Acc: 72.37%
Epoch 12/100, Train Loss: 0.850667, Train Acc: 70.04%, Val Loss: 0.807521, Val Acc: 71.58%
Epoch 13/100, Train Loss: 0.842749, Train Acc: 70.15%, Val Loss: 0.794246, Val Acc: 72.43%
Epoch 14/100, Train Loss: 0.843360, Train Acc: 70.23%, Val Loss: 0.795415, Val Acc: 72.48%
Epoch 15/100, Train Loss: 0.841613, Train Acc: 70.26%, Val Loss: 0.789882, Val Acc: 72.72%
Epoch 16/100, Train Loss: 0.841792, Train Acc: 70.26%, Val Loss: 0.784558, Val Acc: 72.42%
Epoch 17/100, Train Loss: 0.842740, Train Acc: 70.07%, Val Loss: 0.786828, Val Acc: 72.22%
Epoch 18/100, Train Loss: 0.839453, Train Acc: 70.47%, Val Loss: 0.788409, Val Acc: 72.46%
Epoch 19/100, Train Loss: 0.834706, Train Acc: 70.80%, Val Loss: 0.794283, Val Acc: 72.37%
Epoch 20/100, Train Loss: 0.833636, Train Acc: 70.76%, Val Loss: 0.779495, Val Acc: 72.97%
Epoch 21/100, Train Loss: 0.831470, Train Acc: 70.72%, Val Loss: 0.804202, Val Acc: 71.95%
Epoch 22/100, Train Loss: 0.830027, Train Acc: 70.48%, Val Loss: 0.789396, Val Acc: 72.25%
Epoch 23/100, Train Loss: 0.825204, Train Acc: 71.03%, Val Loss: 0.793767, Val Acc: 72.64%
Epoch 24/100, Train Loss: 0.827549, Train Acc: 70.87%, Val Loss: 0.783398, Val Acc: 72.39%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7225}]
Valore m[value]:  0.7225
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7225
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.820916, Train Acc: 71.15%, Val Loss: 0.791549, Val Acc: 72.17%
Epoch 2/100, Train Loss: 0.821789, Train Acc: 70.82%, Val Loss: 0.785020, Val Acc: 72.52%
Epoch 3/100, Train Loss: 0.816935, Train Acc: 71.13%, Val Loss: 0.770922, Val Acc: 73.13%
Epoch 4/100, Train Loss: 0.821295, Train Acc: 71.26%, Val Loss: 0.777286, Val Acc: 72.95%
Epoch 5/100, Train Loss: 0.813121, Train Acc: 71.39%, Val Loss: 0.766980, Val Acc: 73.44%
Epoch 6/100, Train Loss: 0.811421, Train Acc: 71.39%, Val Loss: 0.768214, Val Acc: 73.73%
Epoch 7/100, Train Loss: 0.812853, Train Acc: 71.37%, Val Loss: 0.769214, Val Acc: 73.15%
Epoch 8/100, Train Loss: 0.811811, Train Acc: 71.30%, Val Loss: 0.766075, Val Acc: 73.51%
Epoch 9/100, Train Loss: 0.808834, Train Acc: 71.51%, Val Loss: 0.782766, Val Acc: 72.77%
Epoch 10/100, Train Loss: 0.805175, Train Acc: 71.72%, Val Loss: 0.761965, Val Acc: 73.45%
Epoch 11/100, Train Loss: 0.799007, Train Acc: 71.85%, Val Loss: 0.769501, Val Acc: 73.62%
Epoch 12/100, Train Loss: 0.802012, Train Acc: 71.75%, Val Loss: 0.752988, Val Acc: 73.60%
Epoch 13/100, Train Loss: 0.798927, Train Acc: 71.85%, Val Loss: 0.760799, Val Acc: 73.67%
Epoch 14/100, Train Loss: 0.800980, Train Acc: 71.65%, Val Loss: 0.754165, Val Acc: 74.00%
Epoch 15/100, Train Loss: 0.796681, Train Acc: 72.03%, Val Loss: 0.763053, Val Acc: 73.79%
Epoch 16/100, Train Loss: 0.793554, Train Acc: 72.07%, Val Loss: 0.763677, Val Acc: 73.64%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7342}]
Valore m[value]:  0.7342
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7342
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.793304, Train Acc: 71.90%, Val Loss: 0.753016, Val Acc: 73.80%
Epoch 2/100, Train Loss: 0.790832, Train Acc: 72.17%, Val Loss: 0.758125, Val Acc: 73.77%
Epoch 3/100, Train Loss: 0.788310, Train Acc: 72.30%, Val Loss: 0.759601, Val Acc: 74.02%
Epoch 4/100, Train Loss: 0.788512, Train Acc: 72.16%, Val Loss: 0.767029, Val Acc: 73.42%
Epoch 5/100, Train Loss: 0.787139, Train Acc: 72.30%, Val Loss: 0.749881, Val Acc: 73.92%
Epoch 6/100, Train Loss: 0.788525, Train Acc: 72.19%, Val Loss: 0.747372, Val Acc: 74.44%
Epoch 7/100, Train Loss: 0.786515, Train Acc: 72.36%, Val Loss: 0.755317, Val Acc: 73.90%
Epoch 8/100, Train Loss: 0.785589, Train Acc: 72.45%, Val Loss: 0.749741, Val Acc: 73.93%
Epoch 9/100, Train Loss: 0.780446, Train Acc: 72.72%, Val Loss: 0.739912, Val Acc: 74.42%
Epoch 10/100, Train Loss: 0.780813, Train Acc: 72.50%, Val Loss: 0.747308, Val Acc: 74.30%
Epoch 11/100, Train Loss: 0.779510, Train Acc: 72.36%, Val Loss: 0.743082, Val Acc: 74.52%
Epoch 12/100, Train Loss: 0.776409, Train Acc: 72.57%, Val Loss: 0.743328, Val Acc: 74.37%
Epoch 13/100, Train Loss: 0.773785, Train Acc: 72.73%, Val Loss: 0.749534, Val Acc: 74.31%
Epoch 14/100, Train Loss: 0.771393, Train Acc: 72.66%, Val Loss: 0.736971, Val Acc: 74.69%
Epoch 15/100, Train Loss: 0.775752, Train Acc: 72.74%, Val Loss: 0.739564, Val Acc: 74.26%
Epoch 16/100, Train Loss: 0.775438, Train Acc: 72.81%, Val Loss: 0.728986, Val Acc: 74.92%
Epoch 17/100, Train Loss: 0.768472, Train Acc: 73.01%, Val Loss: 0.734317, Val Acc: 74.68%
Epoch 18/100, Train Loss: 0.771521, Train Acc: 72.76%, Val Loss: 0.731485, Val Acc: 74.64%
Epoch 19/100, Train Loss: 0.770313, Train Acc: 72.86%, Val Loss: 0.742802, Val Acc: 74.56%
Epoch 20/100, Train Loss: 0.766328, Train Acc: 73.05%, Val Loss: 0.731508, Val Acc: 74.81%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7467}]
Valore m[value]:  0.7467
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.7467
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 0.767892, Train Acc: 72.94%, Val Loss: 0.729612, Val Acc: 75.02%
Epoch 2/100, Train Loss: 0.762977, Train Acc: 73.20%, Val Loss: 0.730389, Val Acc: 74.81%
Epoch 3/100, Train Loss: 0.760784, Train Acc: 73.16%, Val Loss: 0.720923, Val Acc: 74.97%
Epoch 4/100, Train Loss: 0.757257, Train Acc: 73.58%, Val Loss: 0.748523, Val Acc: 74.59%
Epoch 5/100, Train Loss: 0.759272, Train Acc: 73.35%, Val Loss: 0.718321, Val Acc: 75.47%
Epoch 6/100, Train Loss: 0.758343, Train Acc: 73.36%, Val Loss: 0.730168, Val Acc: 75.11%
Epoch 7/100, Train Loss: 0.755339, Train Acc: 73.57%, Val Loss: 0.728088, Val Acc: 74.78%
Epoch 8/100, Train Loss: 0.756421, Train Acc: 73.41%, Val Loss: 0.732342, Val Acc: 74.80%
Epoch 9/100, Train Loss: 0.757578, Train Acc: 73.51%, Val Loss: 0.721162, Val Acc: 75.53%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.7557}]
Valore m[value]:  0.7557
	Requirements satisfied! Reducing model ... 
Saving mid model... 
Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 1 feature
Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 4 feature
Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 4 feature
Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 4 feature
Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
BatchNorm aggiornato con 8 feature
Reduction operations:
[{'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'reduce_depth', 'val': 17},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 15},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 12},
 {'op': 'scale_feats', 'val': 0.5},
 {'op': 'reduce_depth', 'val': 1},
 {'op': 'scale_feats', 'val': 0.5}]
Reduction ratio: 0.65
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (12): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
------------------------------------------------------------------------------
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (12): Sequential(
    (0): Linear(in_features=392, out_features=10, bias=True)
  )
)
Epoch 1/100, Train Loss: 2.242999, Train Acc: 14.90%, Val Loss: 2.054526, Val Acc: 23.18%
Epoch 2/100, Train Loss: 2.058777, Train Acc: 21.28%, Val Loss: 1.927654, Val Acc: 28.16%
Epoch 3/100, Train Loss: 1.965890, Train Acc: 24.93%, Val Loss: 1.849046, Val Acc: 30.01%
Epoch 4/100, Train Loss: 1.909431, Train Acc: 27.31%, Val Loss: 1.815307, Val Acc: 32.15%
Epoch 5/100, Train Loss: 1.867664, Train Acc: 29.64%, Val Loss: 1.774042, Val Acc: 33.72%
Epoch 6/100, Train Loss: 1.840838, Train Acc: 30.85%, Val Loss: 1.744643, Val Acc: 35.63%
Epoch 7/100, Train Loss: 1.800179, Train Acc: 32.64%, Val Loss: 1.698449, Val Acc: 36.85%
Epoch 8/100, Train Loss: 1.771472, Train Acc: 33.99%, Val Loss: 1.667749, Val Acc: 37.97%
Epoch 9/100, Train Loss: 1.741081, Train Acc: 35.17%, Val Loss: 1.640959, Val Acc: 40.25%
Epoch 10/100, Train Loss: 1.722330, Train Acc: 36.34%, Val Loss: 1.618471, Val Acc: 41.10%
Epoch 11/100, Train Loss: 1.702567, Train Acc: 37.08%, Val Loss: 1.597964, Val Acc: 41.90%
Epoch 12/100, Train Loss: 1.680181, Train Acc: 37.88%, Val Loss: 1.583445, Val Acc: 42.57%
Epoch 13/100, Train Loss: 1.664670, Train Acc: 38.83%, Val Loss: 1.566515, Val Acc: 42.95%
Epoch 14/100, Train Loss: 1.654394, Train Acc: 39.56%, Val Loss: 1.547132, Val Acc: 43.76%
Epoch 15/100, Train Loss: 1.640722, Train Acc: 40.13%, Val Loss: 1.534305, Val Acc: 44.22%
Epoch 16/100, Train Loss: 1.627172, Train Acc: 40.47%, Val Loss: 1.518631, Val Acc: 44.92%
Epoch 17/100, Train Loss: 1.615870, Train Acc: 41.01%, Val Loss: 1.516165, Val Acc: 44.89%
Epoch 18/100, Train Loss: 1.604127, Train Acc: 41.17%, Val Loss: 1.500910, Val Acc: 45.46%
Epoch 19/100, Train Loss: 1.596887, Train Acc: 41.57%, Val Loss: 1.494801, Val Acc: 46.30%
Epoch 20/100, Train Loss: 1.587811, Train Acc: 42.15%, Val Loss: 1.485316, Val Acc: 46.05%
Epoch 21/100, Train Loss: 1.581047, Train Acc: 42.30%, Val Loss: 1.468907, Val Acc: 46.56%
Epoch 22/100, Train Loss: 1.569317, Train Acc: 42.90%, Val Loss: 1.462899, Val Acc: 47.30%
Epoch 23/100, Train Loss: 1.561402, Train Acc: 42.96%, Val Loss: 1.451270, Val Acc: 47.62%
Epoch 24/100, Train Loss: 1.550690, Train Acc: 43.40%, Val Loss: 1.447149, Val Acc: 47.65%
Epoch 25/100, Train Loss: 1.542254, Train Acc: 44.12%, Val Loss: 1.449784, Val Acc: 47.53%
Epoch 26/100, Train Loss: 1.538741, Train Acc: 44.09%, Val Loss: 1.429777, Val Acc: 48.40%
Epoch 27/100, Train Loss: 1.521610, Train Acc: 44.74%, Val Loss: 1.409623, Val Acc: 49.22%
Epoch 28/100, Train Loss: 1.522492, Train Acc: 44.69%, Val Loss: 1.410124, Val Acc: 49.21%
Epoch 29/100, Train Loss: 1.509760, Train Acc: 45.17%, Val Loss: 1.401476, Val Acc: 49.08%
Epoch 30/100, Train Loss: 1.503109, Train Acc: 45.27%, Val Loss: 1.387289, Val Acc: 49.68%
Epoch 31/100, Train Loss: 1.499477, Train Acc: 45.77%, Val Loss: 1.386171, Val Acc: 49.59%
Epoch 32/100, Train Loss: 1.491197, Train Acc: 45.97%, Val Loss: 1.373874, Val Acc: 50.35%
Epoch 33/100, Train Loss: 1.483859, Train Acc: 46.29%, Val Loss: 1.365301, Val Acc: 50.64%
Epoch 34/100, Train Loss: 1.477696, Train Acc: 46.49%, Val Loss: 1.358773, Val Acc: 50.69%
Epoch 35/100, Train Loss: 1.473625, Train Acc: 46.51%, Val Loss: 1.351170, Val Acc: 51.01%
Epoch 36/100, Train Loss: 1.464346, Train Acc: 47.18%, Val Loss: 1.349145, Val Acc: 51.06%
Epoch 37/100, Train Loss: 1.456403, Train Acc: 47.26%, Val Loss: 1.337207, Val Acc: 51.66%
Epoch 38/100, Train Loss: 1.449405, Train Acc: 47.78%, Val Loss: 1.326540, Val Acc: 52.15%
Epoch 39/100, Train Loss: 1.442175, Train Acc: 47.93%, Val Loss: 1.322793, Val Acc: 52.55%
Epoch 40/100, Train Loss: 1.434775, Train Acc: 48.33%, Val Loss: 1.313485, Val Acc: 52.63%
Epoch 41/100, Train Loss: 1.435886, Train Acc: 48.15%, Val Loss: 1.311980, Val Acc: 52.71%
Epoch 42/100, Train Loss: 1.428873, Train Acc: 48.72%, Val Loss: 1.308970, Val Acc: 52.76%
Epoch 43/100, Train Loss: 1.413531, Train Acc: 49.00%, Val Loss: 1.297232, Val Acc: 53.27%
Epoch 44/100, Train Loss: 1.417652, Train Acc: 49.06%, Val Loss: 1.307075, Val Acc: 52.61%
Epoch 45/100, Train Loss: 1.411320, Train Acc: 49.28%, Val Loss: 1.285212, Val Acc: 53.92%
Epoch 46/100, Train Loss: 1.402057, Train Acc: 49.59%, Val Loss: 1.280355, Val Acc: 53.91%
Epoch 47/100, Train Loss: 1.398087, Train Acc: 49.99%, Val Loss: 1.275186, Val Acc: 53.97%
Epoch 48/100, Train Loss: 1.390640, Train Acc: 50.15%, Val Loss: 1.270563, Val Acc: 54.28%
Epoch 49/100, Train Loss: 1.385833, Train Acc: 50.02%, Val Loss: 1.263330, Val Acc: 54.51%
Epoch 50/100, Train Loss: 1.376860, Train Acc: 50.56%, Val Loss: 1.262376, Val Acc: 54.72%
Epoch 51/100, Train Loss: 1.379053, Train Acc: 50.61%, Val Loss: 1.253153, Val Acc: 54.96%
Epoch 52/100, Train Loss: 1.369673, Train Acc: 51.03%, Val Loss: 1.256317, Val Acc: 54.93%
Epoch 53/100, Train Loss: 1.363251, Train Acc: 51.17%, Val Loss: 1.247603, Val Acc: 55.16%
Epoch 54/100, Train Loss: 1.359795, Train Acc: 51.36%, Val Loss: 1.241416, Val Acc: 55.33%
Epoch 55/100, Train Loss: 1.357137, Train Acc: 51.59%, Val Loss: 1.238126, Val Acc: 55.48%
Epoch 56/100, Train Loss: 1.352635, Train Acc: 51.55%, Val Loss: 1.236655, Val Acc: 55.72%
Epoch 57/100, Train Loss: 1.349887, Train Acc: 51.54%, Val Loss: 1.238005, Val Acc: 55.49%
Epoch 58/100, Train Loss: 1.345270, Train Acc: 51.98%, Val Loss: 1.229360, Val Acc: 55.85%
Epoch 59/100, Train Loss: 1.338155, Train Acc: 52.08%, Val Loss: 1.227753, Val Acc: 56.08%
Epoch 60/100, Train Loss: 1.341205, Train Acc: 51.93%, Val Loss: 1.221859, Val Acc: 55.97%
Epoch 61/100, Train Loss: 1.332526, Train Acc: 52.46%, Val Loss: 1.220762, Val Acc: 56.28%
Epoch 62/100, Train Loss: 1.326207, Train Acc: 52.52%, Val Loss: 1.213803, Val Acc: 56.33%
Epoch 63/100, Train Loss: 1.318926, Train Acc: 52.71%, Val Loss: 1.214335, Val Acc: 56.45%
Epoch 64/100, Train Loss: 1.316522, Train Acc: 52.82%, Val Loss: 1.207257, Val Acc: 56.64%
Epoch 65/100, Train Loss: 1.318643, Train Acc: 52.67%, Val Loss: 1.207048, Val Acc: 57.01%
Epoch 66/100, Train Loss: 1.313980, Train Acc: 52.85%, Val Loss: 1.210865, Val Acc: 56.78%
Epoch 67/100, Train Loss: 1.304094, Train Acc: 53.35%, Val Loss: 1.199210, Val Acc: 57.20%
Epoch 68/100, Train Loss: 1.308017, Train Acc: 53.07%, Val Loss: 1.192485, Val Acc: 57.60%
Epoch 69/100, Train Loss: 1.302668, Train Acc: 53.58%, Val Loss: 1.194609, Val Acc: 57.58%
Epoch 70/100, Train Loss: 1.301975, Train Acc: 53.67%, Val Loss: 1.192660, Val Acc: 57.34%
Epoch 71/100, Train Loss: 1.301792, Train Acc: 53.56%, Val Loss: 1.192245, Val Acc: 57.49%
Epoch 72/100, Train Loss: 1.294296, Train Acc: 53.54%, Val Loss: 1.185440, Val Acc: 57.75%
Epoch 73/100, Train Loss: 1.292092, Train Acc: 53.80%, Val Loss: 1.180458, Val Acc: 57.71%
Epoch 74/100, Train Loss: 1.284865, Train Acc: 54.01%, Val Loss: 1.175166, Val Acc: 58.12%
Epoch 75/100, Train Loss: 1.285553, Train Acc: 54.05%, Val Loss: 1.177313, Val Acc: 57.78%
Epoch 76/100, Train Loss: 1.283470, Train Acc: 54.33%, Val Loss: 1.171365, Val Acc: 58.42%
Epoch 77/100, Train Loss: 1.280051, Train Acc: 54.05%, Val Loss: 1.172495, Val Acc: 58.39%
Epoch 78/100, Train Loss: 1.279701, Train Acc: 54.42%, Val Loss: 1.180189, Val Acc: 58.07%
Epoch 79/100, Train Loss: 1.277732, Train Acc: 54.01%, Val Loss: 1.168320, Val Acc: 58.23%
Epoch 80/100, Train Loss: 1.271504, Train Acc: 54.57%, Val Loss: 1.161513, Val Acc: 58.67%
Epoch 81/100, Train Loss: 1.271837, Train Acc: 54.52%, Val Loss: 1.160502, Val Acc: 58.70%
Epoch 82/100, Train Loss: 1.267747, Train Acc: 54.96%, Val Loss: 1.159420, Val Acc: 58.54%
Epoch 83/100, Train Loss: 1.269605, Train Acc: 54.44%, Val Loss: 1.160737, Val Acc: 58.73%
Epoch 84/100, Train Loss: 1.264964, Train Acc: 54.73%, Val Loss: 1.159549, Val Acc: 58.73%
Epoch 85/100, Train Loss: 1.262911, Train Acc: 54.84%, Val Loss: 1.156277, Val Acc: 58.62%
Epoch 86/100, Train Loss: 1.262113, Train Acc: 54.91%, Val Loss: 1.150543, Val Acc: 59.02%
Epoch 87/100, Train Loss: 1.261021, Train Acc: 55.12%, Val Loss: 1.149548, Val Acc: 58.93%
Epoch 88/100, Train Loss: 1.249945, Train Acc: 55.20%, Val Loss: 1.152150, Val Acc: 58.79%
Epoch 89/100, Train Loss: 1.254772, Train Acc: 55.27%, Val Loss: 1.150590, Val Acc: 58.88%
Epoch 90/100, Train Loss: 1.251944, Train Acc: 55.29%, Val Loss: 1.151039, Val Acc: 58.78%
Epoch 91/100, Train Loss: 1.246040, Train Acc: 55.36%, Val Loss: 1.147888, Val Acc: 59.27%
Epoch 92/100, Train Loss: 1.247765, Train Acc: 55.47%, Val Loss: 1.142641, Val Acc: 59.49%
Epoch 93/100, Train Loss: 1.244173, Train Acc: 55.69%, Val Loss: 1.143325, Val Acc: 59.45%
Epoch 94/100, Train Loss: 1.240669, Train Acc: 55.74%, Val Loss: 1.141111, Val Acc: 59.38%
Epoch 95/100, Train Loss: 1.237746, Train Acc: 55.64%, Val Loss: 1.140441, Val Acc: 59.57%
Epoch 96/100, Train Loss: 1.238798, Train Acc: 55.85%, Val Loss: 1.132116, Val Acc: 59.67%
Epoch 97/100, Train Loss: 1.237541, Train Acc: 55.62%, Val Loss: 1.143357, Val Acc: 59.07%
Epoch 98/100, Train Loss: 1.236967, Train Acc: 55.76%, Val Loss: 1.133880, Val Acc: 59.51%
Epoch 99/100, Train Loss: 1.230305, Train Acc: 56.13%, Val Loss: 1.132848, Val Acc: 59.74%
Epoch 100/100, Train Loss: 1.233250, Train Acc: 56.10%, Val Loss: 1.132929, Val Acc: 59.60%
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.596}]
Valore m[value]:  0.596
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.596
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.226987, Train Acc: 56.06%, Val Loss: 1.124484, Val Acc: 60.33%
Epoch 2/100, Train Loss: 1.230130, Train Acc: 55.84%, Val Loss: 1.123384, Val Acc: 59.90%
Epoch 3/100, Train Loss: 1.224897, Train Acc: 56.27%, Val Loss: 1.133172, Val Acc: 59.80%
Epoch 4/100, Train Loss: 1.227744, Train Acc: 56.37%, Val Loss: 1.129419, Val Acc: 59.77%
Epoch 5/100, Train Loss: 1.218621, Train Acc: 56.55%, Val Loss: 1.123210, Val Acc: 60.09%
Epoch 6/100, Train Loss: 1.218923, Train Acc: 56.66%, Val Loss: 1.129168, Val Acc: 59.77%
Epoch 7/100, Train Loss: 1.220793, Train Acc: 56.63%, Val Loss: 1.121087, Val Acc: 60.06%
Epoch 8/100, Train Loss: 1.220563, Train Acc: 56.40%, Val Loss: 1.131340, Val Acc: 59.63%
Epoch 9/100, Train Loss: 1.213382, Train Acc: 56.75%, Val Loss: 1.125561, Val Acc: 59.97%
Epoch 10/100, Train Loss: 1.219745, Train Acc: 56.68%, Val Loss: 1.121069, Val Acc: 60.11%
Epoch 11/100, Train Loss: 1.215039, Train Acc: 56.58%, Val Loss: 1.133059, Val Acc: 59.74%
Epoch 12/100, Train Loss: 1.212008, Train Acc: 56.77%, Val Loss: 1.116073, Val Acc: 60.23%
Epoch 13/100, Train Loss: 1.212986, Train Acc: 56.50%, Val Loss: 1.112626, Val Acc: 60.26%
Epoch 14/100, Train Loss: 1.212015, Train Acc: 56.66%, Val Loss: 1.113324, Val Acc: 60.29%
Epoch 15/100, Train Loss: 1.201642, Train Acc: 57.20%, Val Loss: 1.111627, Val Acc: 60.69%
Epoch 16/100, Train Loss: 1.204774, Train Acc: 56.89%, Val Loss: 1.113125, Val Acc: 60.16%
Epoch 17/100, Train Loss: 1.201841, Train Acc: 57.28%, Val Loss: 1.110397, Val Acc: 60.25%
Epoch 18/100, Train Loss: 1.205118, Train Acc: 57.11%, Val Loss: 1.107001, Val Acc: 60.68%
Epoch 19/100, Train Loss: 1.200965, Train Acc: 57.18%, Val Loss: 1.106870, Val Acc: 60.62%
Epoch 20/100, Train Loss: 1.201040, Train Acc: 57.04%, Val Loss: 1.108065, Val Acc: 60.82%
Epoch 21/100, Train Loss: 1.199557, Train Acc: 57.11%, Val Loss: 1.105143, Val Acc: 60.29%
Epoch 22/100, Train Loss: 1.201246, Train Acc: 57.11%, Val Loss: 1.101643, Val Acc: 60.66%
Epoch 23/100, Train Loss: 1.203071, Train Acc: 57.21%, Val Loss: 1.103359, Val Acc: 60.89%
Epoch 24/100, Train Loss: 1.198967, Train Acc: 57.32%, Val Loss: 1.099679, Val Acc: 60.77%
Epoch 25/100, Train Loss: 1.192434, Train Acc: 57.36%, Val Loss: 1.104151, Val Acc: 60.59%
Epoch 26/100, Train Loss: 1.191560, Train Acc: 57.38%, Val Loss: 1.095649, Val Acc: 60.82%
Epoch 27/100, Train Loss: 1.197631, Train Acc: 57.28%, Val Loss: 1.106767, Val Acc: 60.23%
Epoch 28/100, Train Loss: 1.189151, Train Acc: 57.54%, Val Loss: 1.097159, Val Acc: 60.84%
Epoch 29/100, Train Loss: 1.192174, Train Acc: 57.36%, Val Loss: 1.095180, Val Acc: 60.77%
Epoch 30/100, Train Loss: 1.190054, Train Acc: 57.33%, Val Loss: 1.103559, Val Acc: 60.43%
Epoch 31/100, Train Loss: 1.189398, Train Acc: 57.37%, Val Loss: 1.089818, Val Acc: 61.05%
Epoch 32/100, Train Loss: 1.192050, Train Acc: 57.70%, Val Loss: 1.090106, Val Acc: 61.23%
Epoch 33/100, Train Loss: 1.184296, Train Acc: 57.72%, Val Loss: 1.091514, Val Acc: 61.15%
Epoch 34/100, Train Loss: 1.180431, Train Acc: 57.84%, Val Loss: 1.091830, Val Acc: 60.79%
Epoch 35/100, Train Loss: 1.180156, Train Acc: 57.98%, Val Loss: 1.092767, Val Acc: 61.06%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6062}]
Valore m[value]:  0.6062
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6062
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.177391, Train Acc: 58.10%, Val Loss: 1.090351, Val Acc: 61.18%
Epoch 2/100, Train Loss: 1.180053, Train Acc: 58.01%, Val Loss: 1.085959, Val Acc: 61.29%
Epoch 3/100, Train Loss: 1.180098, Train Acc: 57.85%, Val Loss: 1.080104, Val Acc: 61.18%
Epoch 4/100, Train Loss: 1.176028, Train Acc: 57.91%, Val Loss: 1.084378, Val Acc: 61.39%
Epoch 5/100, Train Loss: 1.178112, Train Acc: 58.11%, Val Loss: 1.094831, Val Acc: 60.89%
Epoch 6/100, Train Loss: 1.178350, Train Acc: 57.77%, Val Loss: 1.081915, Val Acc: 61.32%
Epoch 7/100, Train Loss: 1.175985, Train Acc: 58.13%, Val Loss: 1.086823, Val Acc: 61.34%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6093}]
Valore m[value]:  0.6093
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6093
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.173951, Train Acc: 58.35%, Val Loss: 1.082217, Val Acc: 61.17%
Epoch 2/100, Train Loss: 1.171606, Train Acc: 58.07%, Val Loss: 1.080967, Val Acc: 61.56%
Epoch 3/100, Train Loss: 1.173248, Train Acc: 58.29%, Val Loss: 1.090633, Val Acc: 60.79%
Epoch 4/100, Train Loss: 1.172223, Train Acc: 58.04%, Val Loss: 1.079324, Val Acc: 61.47%
Epoch 5/100, Train Loss: 1.165169, Train Acc: 58.35%, Val Loss: 1.077879, Val Acc: 61.58%
Epoch 6/100, Train Loss: 1.169227, Train Acc: 58.33%, Val Loss: 1.079221, Val Acc: 61.47%
Epoch 7/100, Train Loss: 1.168095, Train Acc: 58.39%, Val Loss: 1.074022, Val Acc: 61.43%
Epoch 8/100, Train Loss: 1.168136, Train Acc: 58.38%, Val Loss: 1.080761, Val Acc: 61.16%
Epoch 9/100, Train Loss: 1.166861, Train Acc: 58.44%, Val Loss: 1.074835, Val Acc: 61.69%
Epoch 10/100, Train Loss: 1.165010, Train Acc: 58.36%, Val Loss: 1.082762, Val Acc: 61.24%
Epoch 11/100, Train Loss: 1.167181, Train Acc: 58.28%, Val Loss: 1.075021, Val Acc: 61.59%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6178}]
Valore m[value]:  0.6178
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6178
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.156746, Train Acc: 58.73%, Val Loss: 1.093700, Val Acc: 61.03%
Epoch 2/100, Train Loss: 1.162062, Train Acc: 58.52%, Val Loss: 1.070816, Val Acc: 61.67%
Epoch 3/100, Train Loss: 1.158016, Train Acc: 58.61%, Val Loss: 1.065713, Val Acc: 62.30%
Epoch 4/100, Train Loss: 1.161758, Train Acc: 58.50%, Val Loss: 1.068443, Val Acc: 61.69%
Epoch 5/100, Train Loss: 1.160527, Train Acc: 58.52%, Val Loss: 1.069886, Val Acc: 61.63%
Epoch 6/100, Train Loss: 1.157339, Train Acc: 58.75%, Val Loss: 1.079293, Val Acc: 61.55%
Epoch 7/100, Train Loss: 1.157926, Train Acc: 58.80%, Val Loss: 1.064273, Val Acc: 62.18%
Epoch 8/100, Train Loss: 1.152286, Train Acc: 58.74%, Val Loss: 1.069330, Val Acc: 61.77%
Epoch 9/100, Train Loss: 1.156603, Train Acc: 58.71%, Val Loss: 1.061639, Val Acc: 62.06%
Epoch 10/100, Train Loss: 1.147875, Train Acc: 59.11%, Val Loss: 1.066749, Val Acc: 61.95%
Epoch 11/100, Train Loss: 1.149032, Train Acc: 58.95%, Val Loss: 1.068164, Val Acc: 61.76%
Epoch 12/100, Train Loss: 1.147859, Train Acc: 58.93%, Val Loss: 1.060320, Val Acc: 62.46%
Epoch 13/100, Train Loss: 1.150751, Train Acc: 58.85%, Val Loss: 1.076102, Val Acc: 61.59%
Epoch 14/100, Train Loss: 1.152036, Train Acc: 58.70%, Val Loss: 1.063205, Val Acc: 61.82%
Epoch 15/100, Train Loss: 1.145495, Train Acc: 59.05%, Val Loss: 1.066983, Val Acc: 61.71%
Epoch 16/100, Train Loss: 1.149642, Train Acc: 58.96%, Val Loss: 1.058390, Val Acc: 62.33%
Epoch 17/100, Train Loss: 1.145083, Train Acc: 59.11%, Val Loss: 1.059551, Val Acc: 62.15%
Epoch 18/100, Train Loss: 1.144217, Train Acc: 59.06%, Val Loss: 1.072386, Val Acc: 61.50%
Epoch 19/100, Train Loss: 1.147529, Train Acc: 59.12%, Val Loss: 1.059170, Val Acc: 62.23%
Epoch 20/100, Train Loss: 1.139383, Train Acc: 59.26%, Val Loss: 1.056505, Val Acc: 62.28%
Epoch 21/100, Train Loss: 1.145337, Train Acc: 59.40%, Val Loss: 1.062115, Val Acc: 61.91%
Epoch 22/100, Train Loss: 1.139173, Train Acc: 59.34%, Val Loss: 1.061298, Val Acc: 62.19%
Epoch 23/100, Train Loss: 1.143596, Train Acc: 59.34%, Val Loss: 1.057986, Val Acc: 62.32%
Epoch 24/100, Train Loss: 1.141029, Train Acc: 59.05%, Val Loss: 1.052143, Val Acc: 62.33%
Epoch 25/100, Train Loss: 1.144734, Train Acc: 59.13%, Val Loss: 1.055418, Val Acc: 62.49%
Epoch 26/100, Train Loss: 1.144441, Train Acc: 59.06%, Val Loss: 1.055960, Val Acc: 62.60%
Epoch 27/100, Train Loss: 1.138921, Train Acc: 59.54%, Val Loss: 1.058287, Val Acc: 62.14%
Epoch 28/100, Train Loss: 1.140034, Train Acc: 59.20%, Val Loss: 1.050263, Val Acc: 62.64%
Epoch 29/100, Train Loss: 1.141436, Train Acc: 59.27%, Val Loss: 1.056975, Val Acc: 62.24%
Epoch 30/100, Train Loss: 1.140050, Train Acc: 59.09%, Val Loss: 1.060002, Val Acc: 62.26%
Epoch 31/100, Train Loss: 1.141737, Train Acc: 59.18%, Val Loss: 1.066324, Val Acc: 61.99%
Epoch 32/100, Train Loss: 1.138992, Train Acc: 59.46%, Val Loss: 1.045488, Val Acc: 62.68%
Epoch 33/100, Train Loss: 1.134099, Train Acc: 59.49%, Val Loss: 1.050725, Val Acc: 62.56%
Epoch 34/100, Train Loss: 1.137901, Train Acc: 59.30%, Val Loss: 1.053181, Val Acc: 62.28%
Epoch 35/100, Train Loss: 1.135557, Train Acc: 59.32%, Val Loss: 1.054719, Val Acc: 62.50%
Epoch 36/100, Train Loss: 1.131854, Train Acc: 59.79%, Val Loss: 1.057263, Val Acc: 62.00%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6278}]
Valore m[value]:  0.6278
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6278
	Requirements not satisfied! Continue training ... 
Reached half of the maximum attempts, reallocating model...
Epoch 1/100, Train Loss: 1.133538, Train Acc: 59.50%, Val Loss: 1.045010, Val Acc: 62.78%
Epoch 2/100, Train Loss: 1.136858, Train Acc: 59.44%, Val Loss: 1.043395, Val Acc: 62.77%
Epoch 3/100, Train Loss: 1.132670, Train Acc: 59.49%, Val Loss: 1.056796, Val Acc: 62.15%
Epoch 4/100, Train Loss: 1.136048, Train Acc: 59.45%, Val Loss: 1.047516, Val Acc: 62.67%
Epoch 5/100, Train Loss: 1.132203, Train Acc: 59.51%, Val Loss: 1.057487, Val Acc: 61.87%
Epoch 6/100, Train Loss: 1.128119, Train Acc: 59.41%, Val Loss: 1.041959, Val Acc: 62.88%
Epoch 7/100, Train Loss: 1.133184, Train Acc: 59.49%, Val Loss: 1.040864, Val Acc: 62.92%
Epoch 8/100, Train Loss: 1.130097, Train Acc: 59.47%, Val Loss: 1.039387, Val Acc: 63.29%
Epoch 9/100, Train Loss: 1.131406, Train Acc: 59.53%, Val Loss: 1.038761, Val Acc: 63.23%
Epoch 10/100, Train Loss: 1.130384, Train Acc: 59.60%, Val Loss: 1.046762, Val Acc: 62.75%
Epoch 11/100, Train Loss: 1.125257, Train Acc: 59.85%, Val Loss: 1.058965, Val Acc: 62.58%
Epoch 12/100, Train Loss: 1.128052, Train Acc: 59.96%, Val Loss: 1.046753, Val Acc: 63.04%
Epoch 13/100, Train Loss: 1.133223, Train Acc: 59.69%, Val Loss: 1.046216, Val Acc: 62.71%
Epoch 14/100, Train Loss: 1.129443, Train Acc: 59.74%, Val Loss: 1.036531, Val Acc: 63.44%
Epoch 15/100, Train Loss: 1.130316, Train Acc: 59.86%, Val Loss: 1.046057, Val Acc: 62.95%
Epoch 16/100, Train Loss: 1.126754, Train Acc: 59.79%, Val Loss: 1.041830, Val Acc: 62.73%
Epoch 17/100, Train Loss: 1.123459, Train Acc: 59.81%, Val Loss: 1.043328, Val Acc: 62.95%
Epoch 18/100, Train Loss: 1.121904, Train Acc: 59.88%, Val Loss: 1.039850, Val Acc: 63.23%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6304}]
Valore m[value]:  0.6304
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6304
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.124226, Train Acc: 59.66%, Val Loss: 1.037509, Val Acc: 63.01%
Epoch 2/100, Train Loss: 1.126546, Train Acc: 60.07%, Val Loss: 1.030863, Val Acc: 63.51%
Epoch 3/100, Train Loss: 1.121357, Train Acc: 59.96%, Val Loss: 1.042287, Val Acc: 62.97%
Epoch 4/100, Train Loss: 1.128553, Train Acc: 59.81%, Val Loss: 1.033503, Val Acc: 63.37%
Epoch 5/100, Train Loss: 1.121406, Train Acc: 60.13%, Val Loss: 1.035824, Val Acc: 62.93%
Epoch 6/100, Train Loss: 1.123000, Train Acc: 60.03%, Val Loss: 1.033863, Val Acc: 63.24%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6367}]
Valore m[value]:  0.6367
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6367
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.117915, Train Acc: 60.07%, Val Loss: 1.031430, Val Acc: 63.16%
Epoch 2/100, Train Loss: 1.122732, Train Acc: 59.98%, Val Loss: 1.054359, Val Acc: 62.54%
Epoch 3/100, Train Loss: 1.121789, Train Acc: 59.80%, Val Loss: 1.041231, Val Acc: 62.99%
Epoch 4/100, Train Loss: 1.119909, Train Acc: 59.99%, Val Loss: 1.037534, Val Acc: 62.81%
Epoch 5/100, Train Loss: 1.119385, Train Acc: 59.98%, Val Loss: 1.030717, Val Acc: 63.39%
Epoch 6/100, Train Loss: 1.117367, Train Acc: 59.96%, Val Loss: 1.053275, Val Acc: 62.40%
Epoch 7/100, Train Loss: 1.117953, Train Acc: 60.11%, Val Loss: 1.028804, Val Acc: 63.20%
Epoch 8/100, Train Loss: 1.114471, Train Acc: 60.53%, Val Loss: 1.038702, Val Acc: 63.03%
Epoch 9/100, Train Loss: 1.119462, Train Acc: 59.67%, Val Loss: 1.031135, Val Acc: 63.58%
Epoch 10/100, Train Loss: 1.119436, Train Acc: 60.03%, Val Loss: 1.033778, Val Acc: 62.91%
Epoch 11/100, Train Loss: 1.117953, Train Acc: 59.98%, Val Loss: 1.052410, Val Acc: 62.64%
Epoch 12/100, Train Loss: 1.114643, Train Acc: 60.34%, Val Loss: 1.026800, Val Acc: 63.68%
Epoch 13/100, Train Loss: 1.120748, Train Acc: 59.92%, Val Loss: 1.031607, Val Acc: 63.61%
Epoch 14/100, Train Loss: 1.117785, Train Acc: 59.92%, Val Loss: 1.041152, Val Acc: 63.21%
Epoch 15/100, Train Loss: 1.115521, Train Acc: 60.22%, Val Loss: 1.027756, Val Acc: 63.69%
Epoch 16/100, Train Loss: 1.112347, Train Acc: 60.24%, Val Loss: 1.037021, Val Acc: 63.33%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6324}]
Valore m[value]:  0.6324
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6324
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.116727, Train Acc: 60.24%, Val Loss: 1.027921, Val Acc: 63.62%
Epoch 2/100, Train Loss: 1.113789, Train Acc: 60.28%, Val Loss: 1.028902, Val Acc: 63.74%
Epoch 3/100, Train Loss: 1.112670, Train Acc: 60.16%, Val Loss: 1.025949, Val Acc: 63.68%
Epoch 4/100, Train Loss: 1.114604, Train Acc: 60.08%, Val Loss: 1.040806, Val Acc: 62.71%
Epoch 5/100, Train Loss: 1.112059, Train Acc: 60.24%, Val Loss: 1.029185, Val Acc: 63.70%
Epoch 6/100, Train Loss: 1.113962, Train Acc: 60.27%, Val Loss: 1.034360, Val Acc: 63.38%
Epoch 7/100, Train Loss: 1.109819, Train Acc: 60.26%, Val Loss: 1.037570, Val Acc: 62.79%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6273}]
Valore m[value]:  0.6273
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6273
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.105740, Train Acc: 60.59%, Val Loss: 1.026031, Val Acc: 63.57%
Epoch 2/100, Train Loss: 1.111116, Train Acc: 60.27%, Val Loss: 1.036215, Val Acc: 63.10%
Epoch 3/100, Train Loss: 1.108523, Train Acc: 60.45%, Val Loss: 1.023824, Val Acc: 63.47%
Epoch 4/100, Train Loss: 1.105896, Train Acc: 60.47%, Val Loss: 1.028803, Val Acc: 63.63%
Epoch 5/100, Train Loss: 1.108508, Train Acc: 60.35%, Val Loss: 1.020041, Val Acc: 64.05%
Epoch 6/100, Train Loss: 1.101598, Train Acc: 60.63%, Val Loss: 1.025202, Val Acc: 63.58%
Epoch 7/100, Train Loss: 1.108112, Train Acc: 60.36%, Val Loss: 1.040417, Val Acc: 63.00%
Epoch 8/100, Train Loss: 1.109252, Train Acc: 60.35%, Val Loss: 1.021099, Val Acc: 63.64%
Epoch 9/100, Train Loss: 1.107762, Train Acc: 60.41%, Val Loss: 1.019572, Val Acc: 64.10%
Epoch 10/100, Train Loss: 1.103518, Train Acc: 60.57%, Val Loss: 1.020263, Val Acc: 63.65%
Epoch 11/100, Train Loss: 1.104387, Train Acc: 60.39%, Val Loss: 1.018944, Val Acc: 63.74%
Epoch 12/100, Train Loss: 1.103598, Train Acc: 60.43%, Val Loss: 1.020345, Val Acc: 63.83%
Epoch 13/100, Train Loss: 1.102288, Train Acc: 60.72%, Val Loss: 1.024626, Val Acc: 63.74%
Epoch 14/100, Train Loss: 1.105764, Train Acc: 60.36%, Val Loss: 1.017042, Val Acc: 63.61%
Epoch 15/100, Train Loss: 1.104277, Train Acc: 60.58%, Val Loss: 1.023323, Val Acc: 63.92%
Epoch 16/100, Train Loss: 1.102021, Train Acc: 60.73%, Val Loss: 1.023005, Val Acc: 63.67%
Epoch 17/100, Train Loss: 1.105760, Train Acc: 60.59%, Val Loss: 1.018519, Val Acc: 63.91%
Epoch 18/100, Train Loss: 1.107545, Train Acc: 60.53%, Val Loss: 1.022102, Val Acc: 63.51%
Epoch 19/100, Train Loss: 1.099306, Train Acc: 60.79%, Val Loss: 1.016306, Val Acc: 63.89%
Epoch 20/100, Train Loss: 1.100854, Train Acc: 60.85%, Val Loss: 1.016740, Val Acc: 63.72%
Epoch 21/100, Train Loss: 1.103440, Train Acc: 60.29%, Val Loss: 1.018216, Val Acc: 64.23%
Epoch 22/100, Train Loss: 1.105555, Train Acc: 60.58%, Val Loss: 1.013598, Val Acc: 64.14%
Epoch 23/100, Train Loss: 1.100592, Train Acc: 60.79%, Val Loss: 1.020819, Val Acc: 63.26%
Epoch 24/100, Train Loss: 1.099428, Train Acc: 60.62%, Val Loss: 1.013823, Val Acc: 64.22%
Epoch 25/100, Train Loss: 1.103953, Train Acc: 60.70%, Val Loss: 1.018331, Val Acc: 63.87%
Epoch 26/100, Train Loss: 1.102170, Train Acc: 60.45%, Val Loss: 1.019632, Val Acc: 63.54%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6383}]
Valore m[value]:  0.6383
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6383
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.104937, Train Acc: 60.61%, Val Loss: 1.009895, Val Acc: 63.93%
Epoch 2/100, Train Loss: 1.102456, Train Acc: 60.73%, Val Loss: 1.008887, Val Acc: 64.35%
Epoch 3/100, Train Loss: 1.102529, Train Acc: 60.71%, Val Loss: 1.012896, Val Acc: 64.18%
Epoch 4/100, Train Loss: 1.101042, Train Acc: 60.50%, Val Loss: 1.016171, Val Acc: 64.11%
Epoch 5/100, Train Loss: 1.100343, Train Acc: 60.94%, Val Loss: 1.009523, Val Acc: 64.13%
Epoch 6/100, Train Loss: 1.098451, Train Acc: 60.82%, Val Loss: 1.033638, Val Acc: 63.36%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6389}]
Valore m[value]:  0.6389
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6389
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.097188, Train Acc: 60.82%, Val Loss: 1.009592, Val Acc: 64.34%
Epoch 2/100, Train Loss: 1.096668, Train Acc: 60.74%, Val Loss: 1.016615, Val Acc: 63.67%
Epoch 3/100, Train Loss: 1.098182, Train Acc: 60.99%, Val Loss: 1.015865, Val Acc: 63.81%
Epoch 4/100, Train Loss: 1.098604, Train Acc: 60.92%, Val Loss: 1.016341, Val Acc: 63.88%
Epoch 5/100, Train Loss: 1.095543, Train Acc: 60.69%, Val Loss: 1.024024, Val Acc: 63.56%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6354}]
Valore m[value]:  0.6354
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6354
	Requirements not satisfied! Continue training ... 
Epoch 1/100, Train Loss: 1.097032, Train Acc: 60.90%, Val Loss: 1.014634, Val Acc: 64.07%
Epoch 2/100, Train Loss: 1.100884, Train Acc: 60.43%, Val Loss: 1.009282, Val Acc: 64.20%
Epoch 3/100, Train Loss: 1.092516, Train Acc: 60.83%, Val Loss: 1.006796, Val Acc: 64.51%
Epoch 4/100, Train Loss: 1.097252, Train Acc: 61.11%, Val Loss: 1.023768, Val Acc: 63.75%
Epoch 5/100, Train Loss: 1.094033, Train Acc: 60.93%, Val Loss: 1.010656, Val Acc: 64.59%
Epoch 6/100, Train Loss: 1.093615, Train Acc: 60.85%, Val Loss: 1.013202, Val Acc: 64.01%
Epoch 7/100, Train Loss: 1.092833, Train Acc: 61.00%, Val Loss: 1.007847, Val Acc: 64.27%
Early stopping triggered.
Training is regular! Checking model requirements ...
Metrics computed = [{'name': 'accuracy', 'value': 0.6408}]
Valore m[value]:  0.6408
	Metric 'accuracy' not satisfied!
	Required 'accuracy' = 0.75 | Computed 'accuracy' = 0.6408
	Requirements not satisfied! Continue training ... 
Loading latest functioning Network...
Original model size:  532.652045249939 MB
Reduced model size:  0.11882495880126953 MB
Parameters Reduction Ratio:  99.98238818982234
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (1): Sequential(
    (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (2): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (3): Sequential(
    (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (4): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (5): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (6): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (7): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (8): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (9): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (10): Sequential(
    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (11): Sequential(
    (0): AdaptiveAvgPool2d(output_size=(7, 7))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Dropout(p=0.5, inplace=False)
  )
  (12): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
Network Reduced in 6748.874177558348 s
